# Task 2 - å‘½åå¯¦é«”è­˜åˆ¥èˆ‡æ™‚é–“æˆ³å°é½Š (NER + Timestamp Alignment)

## ğŸ“‹ ä»»å‹™æ¦‚è¿°

Task 2 æ˜¯ AI Cup 2025 çš„å‘½åå¯¦é«”è­˜åˆ¥ä»»å‹™ï¼Œä¸»è¦ç›®æ¨™æ˜¯ï¼š
1. **å‘½åå¯¦é«”è­˜åˆ¥ (NER)**: å¾é†«ç™‚è½‰éŒ„æ–‡å­—ä¸­è­˜åˆ¥ä¸¦æ¨™è¨»é†«ç™‚ç›¸é—œå¯¦é«”
2. **æ™‚é–“æˆ³å°é½Š**: ç‚ºè­˜åˆ¥å‡ºçš„å¯¦é«”æä¾›ç²¾ç¢ºçš„æ™‚é–“æˆ³è³‡è¨Š
3. **å¤šæ¨¡å‹é›†æˆ**: ä½¿ç”¨å¤šç¨®æ·±åº¦å­¸ç¿’æ¨¡å‹é€²è¡Œé«˜ç²¾åº¦NERé æ¸¬

## ğŸš€ ä¸»è¦åŠŸèƒ½

### 1. å‘½åå¯¦é«”è­˜åˆ¥ (NER)
- ä½¿ç”¨ **XLM-RoBERTa Large** ä½œç‚ºåŸºç¤æ¨¡å‹
- åŠ ä¸ŠCRFå±¤å’ŒFGMè¨“ç·´æ–¹å¼
- æ”¯æ´ 20 ç¨®é†«ç™‚ç›¸é—œå¯¦é«”é¡åˆ¥ï¼š
  - **äººç‰©**: PATIENT, DOCTOR, USERNAME, FAMILYNAME, PERSONALNAME
  - **è·æ¥­**: PROFESSION
  - **åœ°é»**: ROOM, DEPARTMENT, HOSPITAL, ORGANIZATION, STREET, CITY, DISTRICT, COUNTY, STATE, COUNTRY, ZIP, LOCATION-OTHER
  - **æ™‚é–“**: AGE, DATE, TIME, DURATION, SET
  - **è¯çµ¡**: PHONE, FAX, EMAIL, URL, IPADDRESS
  - **è­˜åˆ¥**: SOCIAL_SECURITY_NUMBER, MEDICAL_RECORD_NUMBER, HEALTH_PLAN_NUMBER, ACCOUNT_NUMBER, LICENSE_NUMBER, VEHICLE_ID, DEVICE_ID, BIOMETRIC_ID, ID_NUMBER
  - **å…¶ä»–**: OTHER

### 2. æ™‚é–“æˆ³å°é½Š
- åŸºæ–¼å­—ç¬¦ç´šåˆ¥çš„ç²¾ç¢ºæ™‚é–“æˆ³è¨ˆç®—
- å¯¦é«”åœ¨èªéŸ³ä¸­çš„èµ·å§‹å’ŒçµæŸæ™‚é–“å°é½Š
- æ”¯æ´ word-level å’Œ character-level å°é½Šæ¨¡å¼

### 3. æ¨¡å‹æ¶æ§‹
- **åŸºç¤æ¨¡å‹**: XLM-RoBERTa Large (FacebookAI/xlm-roberta-large-finetuned-conll03-english)
- **æ¢ä»¶éš¨æ©Ÿå ´ (CRF)**: æ”¹å–„åºåˆ—æ¨™è¨»ä¸€è‡´æ€§
- **å°æŠ—è¨“ç·´ (FGM)**: æå‡æ¨¡å‹é­¯æ£’æ€§

## ğŸ“ æª”æ¡ˆçµæ§‹

```
task2/
â”œâ”€â”€ README.md                                  # æœ¬èªªæ˜æ–‡ä»¶
â”œâ”€â”€ NER_CRF_FGM_BIO.ipynb                      # CRF + FGM è¨“ç·´ä¸»ç¨‹å¼
â”œâ”€â”€ predict_all.ipynb                          # æ¨¡å‹é æ¸¬
â”œâ”€â”€ Insert_timestamp.ipynb                     # æ™‚é–“æˆ³å°é½Šè™•ç†
â”œâ”€â”€ generate_task2_test_data_index.ipynb       # ç”¢ç”Ÿä»»å‹™äºŒåœ¨å¥å­ä¸­çš„indexä½ç½®
â”œâ”€â”€ config.json                                # è·¯å¾‘è¨­å®š
```

## ğŸ”§ ç’°å¢ƒè¨­ç½®

### å¿…è¦å¥—ä»¶
```bash
pip install torch
pip install transformers
pip install torchcrf
pip install pytorch-crf
pip install datasets
pip install numpy
pip install pandas
pip install tqdm
```

### æ¨¡å‹è¦æ±‚
- GPU è¨˜æ†¶é«”: å»ºè­° 8GB ä»¥ä¸Š
- CUDA æ”¯æ´: å»ºè­° CUDA 11.0+

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### 1. config.json è¨­å®šèªªæ˜
config.json ç”¨æ–¼é›†ä¸­ç®¡ç†å°ˆæ¡ˆä¸­å„é …æ¨¡å‹èˆ‡è³‡æ–™çš„è·¯å¾‘è¨­å®šï¼Œé¿å…åœ¨ç¨‹å¼ç¢¼ä¸­ç¡¬ç·¨è·¯å¾‘ï¼Œè®“å°ˆæ¡ˆæ›´å®¹æ˜“ç¶­è­·èˆ‡éƒ¨ç½²ã€‚

####ğŸ“ è¨­å®šç¯„ä¾‹

```json
{
  "huggingface_access_token":  "",
  "model_train_task1_data_path_txt": "",
  "model_train_task2_data_path_txt": "",
  "model_val_task1_data_path_txt": "",
  "model_val_task2_data_path_txt": "",
  "model_save_path": "./NER_model",
  "model_logging_dir":"./ner_logs",
  "answer_val_data_path_txt":"",


  "model_predict_all_result_path_txt": "",
  "whisper_timestamp_word_level_path_json": "",
  "whisper_timestamp_char_level_path_json": "",
  "char_level_timestamp_task2_NER_result_path_txt": "",
  "word_level_timestamp_task2_NER_result_path_txt": "",

  "model_checkpoint_1213" : "",
  "model_checkpoint_1000" : "",
  "model_checkpoint_500" : "",
  "model_test_task1_data_path_txt": "",
  "model_test_task2_data_path_txt": ""

}
```

####ğŸ“ æ¬„ä½èªªæ˜

```
æ¬„ä½åç¨±	                                            èªªæ˜
huggingface_access_token                            huggingfaceçš„access_token
model_train_task1_data_path_txt	                    ä»»å‹™ä¸€çš„è¨“ç·´é›†è·¯å¾‘
model_train_task2_data_path_txt                     ä»»å‹™äºŒçš„è¨“ç·´é›†è·¯å¾‘
model_val_task1_data_path_txt                       ä»»å‹™ä¸€çš„é©—è­‰é›†è·¯å¾‘
model_val_task2_data_path_txt                       ä»»å‹™äºŒçš„é©—è­‰é›†è·¯å¾‘
model_save_path                                     æ¨¡å‹å„²å­˜è³‡æ–™å¤¾è·¯å¾‘
model_logging_dir                                   æ¨¡å‹logçš„å„²å­˜è³‡æ–™å¤¾è·¯å¾‘
answer_val_data_path_txt                            é©—è­‰é›†æœ‰indexä½ç½®çš„çµæœè·¯å¾‘

model_predict_all_result_path_txt                   æ¨¡å‹é æ¸¬çš„çµæœ(æœ‰indexä½ç½®)è·¯å¾‘
whisper_timestamp_word_level_path_json              whisperxçš„timestamp word_levelè·¯å¾‘
whisper_timestamp_char_level_path_json              whisperxçš„timestamp char_levelè·¯å¾‘
char_level_timestamp_task2_NER_result_path_txt      char level timestampçš„æ¨¡å‹é æ¸¬çµæœè·¯å¾‘( æŠŠindexæ›æˆtimestamp)
word_level_timestamp_task2_NER_result_path_txt      word level timestampçš„æ¨¡å‹é æ¸¬çµæœè·¯å¾‘( æŠŠindexæ›æˆtimestamp)

model_checkpoint_{è‡ªå·±å‘½å}                          æ¨¡å‹çš„åƒæ•¸è·¯å¾‘
model_test_task1_data_path_txt                      ä»»å‹™ä¸€çš„æ¸¬è©¦é›†è·¯å¾‘
model_test_task2_data_path_txt                      ä»»å‹™äºŒçš„æ¸¬è©¦é›†è·¯å¾‘
```

### 2. ç”¢ç”Ÿtask2çš„SHIåœ¨å¥å­ä¸­çš„indexä½ç½®(å¯ä»¥ç•¶ä½œæ¸¬è©¦) - generate_task2_test_data_index.ipynb

èˆ‰ä¾‹:
```
2505	DURATION	12	22	10 minutes
2505	TIME	115	125	last night
2505	DATE	155	160	today
2505	FAMILYNAME	166	171	James
2943	DATE	225	231	Friday
2943	DATE	248	256	Saturday
2943	DATE	286	293	Tuesday
```

### 3. æ¨¡å‹è¨“ç·´ - NER_CRF_FGM_BIO.ipynb

ä¸»è¦è¨“ç·´è…³æœ¬ï¼Œæ•´åˆäº†å¤šç¨®å…ˆé€²æŠ€è¡“ï¼š

#### ä¸»è¦ç‰¹é»ï¼š
- **CRFå±¤**: ç¢ºä¿æ¨™è¨»åºåˆ—ä¸€è‡´æ€§
- **FGMå°æŠ—è¨“ç·´**: æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- **å­—ç¬¦ç´šè©•ä¼°**: ç²¾ç¢ºçš„æ•ˆèƒ½è©•ä¼°
- **å‹•æ…‹å­¸ç¿’ç‡**: é©æ‡‰æ€§è¨“ç·´ç­–ç•¥

#### è¨“ç·´é…ç½®ï¼š
```python
training_args = TrainingArguments(
    output_dir="./ner_results",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=3e-5,
    num_train_epochs=40,
    weight_decay=0.03,
)
```

### 4. æ¨¡å‹é æ¸¬ - predict_all.ipynb

å¤šæ¨¡å‹é›†æˆé æ¸¬ç³»çµ±ï¼Œæ”¯æ´å¤šç¨®æ¨¡å‹æ¶æ§‹çš„é æ¸¬ï¼š

#### æ”¯æ´çš„æ¨¡å‹é¡å‹ï¼š
- **CRFæ¨¡å‹**: `crf`, `crf_FGM`, `crf_BIOU`
- **Focal Lossæ¨¡å‹**: `focal`, `focal_loss_BIOU`
- **éšå±¤å¼æ¨¡å‹**: `level_1_loss_1`, `level_2_loss_2`
- **æ¬Šé‡èª¿æ•´æ¨¡å‹**: `weight_class`, `weight_class_BIOU`

#### é æ¸¬æµç¨‹ï¼š
```python
# è¼‰å…¥æ¨¡å‹
model = XLMRobertaWithCRF.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# åŸ·è¡Œé æ¸¬
predictions = get_level2_entities_normal(model, tokenizer, text, label_map)
results = Process_Predict_Ner(predictions)
```

### 5. æ™‚é–“æˆ³å°é½Š - Insert_timestamp.ipynb

å°‡ NER çµæœèˆ‡èªéŸ³æ™‚é–“æˆ³å°é½Šï¼š

#### å°é½Šæ–¹æ³•ï¼š
```python
def align_ner_with_whisper(ner_entities, whisper_words):
    for ent in ner_entities:
        ent_start = ent["start"]
        ent_end = ent["end"]
        
        # å°‹æ‰¾é‡ç–Šçš„è©å½™
        matched_words = []
        for word in whisper_words:
            if not (word["char_end"] <= ent_start or word["char_start"] >= ent_end):
                matched_words.append(word)
        
        # åˆ†é…æ™‚é–“æˆ³
        if matched_words:
            ts_start = matched_words[0]['start_time']
            ts_end = matched_words[-1]['end_time']
```

## âš™ï¸ æŠ€è¡“ç‰¹é»

### CRF (æ¢ä»¶éš¨æ©Ÿå ´)
- **åºåˆ—ä¸€è‡´æ€§**: ç¢ºä¿ BIO/BIOU æ¨™è¨»è¦å‰‡
- **å…¨å±€å„ªåŒ–**: è€ƒæ…®æ•´å€‹åºåˆ—çš„æ¨™è¨»æ±ºç­–
- **è½‰ç§»çŸ©é™£**: å­¸ç¿’æ¨™ç±¤é–“çš„è½‰ç§»æ©Ÿç‡

### FGM å°æŠ—è¨“ç·´
- **æ¢¯åº¦æ“¾å‹•**: åœ¨ embedding å±¤åŠ å…¥å°æŠ—å™ªè²
- **é­¯æ£’æ€§æå‡**: å¢å¼·æ¨¡å‹å°è¼¸å…¥è®ŠåŒ–çš„ç©©å®šæ€§
- **æ­£å‰‡åŒ–æ•ˆæœ**: é˜²æ­¢éæ“¬åˆ


## ğŸ“Š æ¨™è¨»æ ¼å¼

### BIO æ ¼å¼
- **B-XXX**: å¯¦é«”é–‹å§‹
- **I-XXX**: å¯¦é«”å…§éƒ¨
- **O**: éå¯¦é«”

### ç¯„ä¾‹
```
ç‹å°æ˜     B-PATIENT
ä»Šå¤©       O
ä¸‹åˆ       B-TIME
ä¸‰é»       I-TIME
```

## ğŸ” è©•ä¼°æŒ‡æ¨™

### å­—ç¬¦ç´šè©•ä¼°
- **ç²¾ç¢ºç‡ (Precision)**: TP / (TP + FP)
- **å¬å›ç‡ (Recall)**: TP / (TP + FN)
- **F1 åˆ†æ•¸**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
- **å®å¹³å‡ F1**: æ‰€æœ‰é¡åˆ¥ F1 çš„å¹³å‡å€¼

### æ™‚é–“é‡ç–Šè©•ä¼°
```python
def calculate_overlap(pred_start, pred_end, gt_start, gt_end):
    overlap_start = max(pred_start, gt_start)
    overlap_end = min(pred_end, gt_end)
    return max(0, overlap_end - overlap_start)
```

## ğŸ¯ æ¨¡å‹æ•ˆèƒ½

### è¨“ç·´ç­–ç•¥
- **æ‰¹æ¬¡å¤§å°**: 4-8 (è¦– GPU è¨˜æ†¶é«”è€Œå®š)
- **å­¸ç¿’ç‡**: 3e-5 (é©åˆé†«ç™‚é ˜åŸŸå¾®èª¿)
- **è¨“ç·´è¼ªæ•¸**: 40 epochs
- **æ¬Šé‡è¡°æ¸›**: 0.03 (é˜²æ­¢éæ“¬åˆ)

### å„ªåŒ–æŠ€å·§
- **æ¢¯åº¦ç´¯ç©**: æ¨¡æ“¬æ›´å¤§çš„æ‰¹æ¬¡å¤§å°
- **å­¸ç¿’ç‡èª¿åº¦**: é¤˜å¼¦é€€ç«æˆ–ç·šæ€§è¡°æ¸›
- **æ—©åœæ©Ÿåˆ¶**: é˜²æ­¢éæ“¬åˆ
- **æ¨¡å‹é›†æˆ**: å¤šå€‹æ¨¡å‹çµæœèåˆ

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ
1. **CUDA è¨˜æ†¶é«”ä¸è¶³**
   - æ¸›å°‘ batch_size
   - ä½¿ç”¨æ¢¯åº¦æª¢æŸ¥é» (gradient checkpointing)
   - å˜—è©¦æ··åˆç²¾åº¦è¨“ç·´

2. **CRF æ”¶æ–‚å•é¡Œ**
   - èª¿æ•´å­¸ç¿’ç‡
   - æª¢æŸ¥æ¨™ç±¤å°æ˜ æ­£ç¢ºæ€§
   - ç¢ºèª mask è¨­ç½®

3. **FGM è¨“ç·´ä¸ç©©å®š**
   - é™ä½ epsilon å€¼
   - èª¿æ•´å°æŠ—è¨“ç·´é »ç‡
   - ç›£æ§æ¢¯åº¦ç¯„æ•¸

### æ•ˆèƒ½å„ªåŒ–
- **æ¨¡å‹é‡åŒ–**: ä½¿ç”¨ INT8 é‡åŒ–æ¸›å°‘è¨˜æ†¶é«”
- **å‹•æ…‹æ‰¹æ¬¡**: æ ¹æ“šåºåˆ—é•·åº¦èª¿æ•´æ‰¹æ¬¡å¤§å°
- **å¿«å–æ©Ÿåˆ¶**: é å…ˆè¨ˆç®— tokenizer çµæœ

## ğŸ“ˆ å¯¦é©—çµæœ

### ğŸ“Š NER æ¨¡å‹çµ„åˆ F1-score æ¯”è¼ƒ

| ç·¨è™Ÿ | æ¨™è¨˜æ–¹å¼ | ä½¿ç”¨æŠ€è¡“              | F1-score | è¨“ç·´æ­¥æ•¸ |
|------|----------|------------------------|----------|----------|
| 1    | BIOU     | baseline               | 0.6856   | 812      |
| 2    | BIOU     | + FGM                  | 0.6698   | 1160     |
| 3    | BIOU     | + CRF                  | 0.7084   | 1276     |
| 4    | BIOU     | + focal loss           | 0.6791   | 1856     |
| 5    | BIOU     | + weight loss          | 0.6497   | 3248     |
| 6    | BIO      | baseline               | 0.6729   | 1044     |
| 7    | BIO      | + FGM                  | 0.6801   | 1624     |
| 8    | BIO      | + CRF                  | 0.7184   | 3016     |
| 9    | BIO      | + focal loss           | 0.7063   | 1508     |
| 10   | BIO      | + weight loss          | 0.6581   | 1856     |
| 11   | BIO      | + CRF + FGM            | **0.7256** | 2088     |

## ğŸ”— ç›¸é—œé€£çµ

- [XLM-RoBERTa](https://huggingface.co/FacebookAI/xlm-roberta-large)
- [TorchCRF](https://pytorch-crf.readthedocs.io/)
- [Transformers](https://huggingface.co/transformers/)
- [AI Cup 2025 å®˜ç¶²](https://aidea-web.tw/topic/cbea3c74-d86b-48c8-8c83-957b2e1374f2)
