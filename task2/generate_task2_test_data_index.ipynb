{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8aaed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config_argument = json.load(f)\n",
    "\n",
    "model_test_task1_data_path_txt = config_argument[\"model_test_task1_data_path_txt\"]\n",
    "model_test_task2_data_path_txt = config_argument[\"model_test_task2_data_path_txt\"]\n",
    "\n",
    "\n",
    "\n",
    "print( \"model_test_task1_data_path_txt\", model_test_task1_data_path_txt )\n",
    "print( \"model_test_task2_data_path_txt\", model_test_task2_data_path_txt ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1199d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 載入 task1 資料：{id: sentence}\n",
    "def load_task1(filepath):\n",
    "    id2text = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                id_, text = parts\n",
    "                id2text[id_] = text\n",
    "    return id2text\n",
    "\n",
    "# 載入 task2 為 DataFrame\n",
    "def load_task2(filepath):\n",
    "    rows = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()  # 先去除行首尾空白與換行\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) == 5:\n",
    "                parts = [p.strip() for p in parts]  # 再去每個欄位的頭尾空白\n",
    "                rows.append(parts)\n",
    "    df = pd.DataFrame(rows, columns=[\"id\", \"type\", \"start_time\", \"end_time\", \"content\"])\n",
    "    return df\n",
    "\n",
    "def find_nth_occurrence(text, substring, n):\n",
    "    start = -1\n",
    "    for _ in range(n):\n",
    "        start = text.find(substring, start + 1)\n",
    "        if start == -1:\n",
    "            return -1\n",
    "    return start\n",
    "\n",
    "\n",
    "def map_entities_to_char_indices_with_duplicates(task1_file, task2_file, output_file=None):\n",
    "    id2text = load_task1(task1_file)\n",
    "    df_task2 = load_task2(task2_file)\n",
    "\n",
    "    # 用來記錄每個 (id, entity_text) 出現次數\n",
    "    occurrence_counter = {}\n",
    "\n",
    "    results = []\n",
    "    for row in df_task2.itertuples():\n",
    "        tid = str(row.id)\n",
    "        entity_text = row.content.strip()\n",
    "        entity_type = row.type\n",
    "\n",
    "        if tid not in id2text:\n",
    "            results.append([tid, entity_type, -1, -1, entity_text])\n",
    "            continue\n",
    "\n",
    "        sentence = id2text[tid]\n",
    "\n",
    "        key = (tid, entity_text)\n",
    "        occurrence_counter[key] = occurrence_counter.get(key, 0) + 1\n",
    "        nth = occurrence_counter[key]\n",
    "\n",
    "        start_char = find_nth_occurrence(sentence, entity_text, nth)\n",
    "        if start_char == -1:\n",
    "            start_char, end_char = -1, -1\n",
    "        else:\n",
    "            end_char = start_char + len(entity_text)\n",
    "\n",
    "        results.append([tid, entity_type, start_char, end_char, entity_text])\n",
    "\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for r in results:\n",
    "                f.write(\"\\t\".join(map(str, r)) + \"\\n\")\n",
    "\n",
    "    return pd.DataFrame(results, columns=['id', 'type', 'start_char', 'end_char', 'content'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322ae92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_result = map_entities_to_char_indices_with_duplicates(\n",
    "    model_test_task1_data_path_txt,\n",
    "    model_test_task2_data_path_txt,\n",
    "    \"./entity_token_indices.txt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
