{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config_argument = json.load(f)\n",
    "\n",
    "access_token = config_argument[\"huggingface_access_token\"]\n",
    "\n",
    "task1_train_data_path_txt = config_argument[\"model_train_task1_data_path_txt\"]\n",
    "task2_train_data_path_txt = config_argument[\"model_train_task2_data_path_txt\"]\n",
    "\n",
    "task1_val_data_path_txt = config_argument[\"model_val_task1_data_path_txt\"]\n",
    "task2_val_data_path_txt = config_argument[\"model_val_task2_data_path_txt\"]\n",
    "\n",
    "answer_val_data_path_txt = config_argument[\"answer_val_data_path_txt\"]\n",
    "\n",
    "model_save_path = config_argument[\"model_save_path\"]\n",
    "model_logging_dir = config_argument[\"model_logging_dir\"]\n",
    "\n",
    "\n",
    "print( \"access_token: \", access_token )\n",
    "print( \"task1_train_data_path: \", task1_train_data_path_txt )\n",
    "print( \"task2_train_data_path: \", task2_train_data_path_txt )\n",
    "print( \"task1_val_data_path: \", task1_val_data_path_txt )\n",
    "print( \"task2_val_data_path: \", task2_val_data_path_txt )\n",
    "print( \"answer_val_data_path: \", answer_val_data_path_txt )\n",
    "print( \"model_save_path: \", model_save_path )\n",
    "print( \"model_logging_dir: \", model_logging_dir )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kg3Bouf1ZdHM",
    "outputId": "aeafd63a-b3b4-474b-a405-6e09a13da7d2"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "from transformers import pipeline\n",
    "\n",
    "access_token = access_token\n",
    "\n",
    "model_id = \"xlm-roberta-large-finetuned-conll03-english\"  # xlm-roberta-large-finetuned-conll03-english\n",
    "\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token ) #padding=True,truncation=True,max_length=128\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id, token=access_token)\n",
    "classifier = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "classifier(\"Alya told Jasmine that Andrew could pay with cash..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcRPLuFtZhPx"
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'O',\n",
    "    1: 'B-PATIENT', 2: 'I-PATIENT', 3: 'L-PATIENT', 4: 'U-PATIENT',\n",
    "    5: 'B-DOCTOR', 6: 'I-DOCTOR', 7: 'L-DOCTOR', 8: 'U-DOCTOR',\n",
    "    9: 'B-USERNAME', 10: 'I-USERNAME', 11: 'L-USERNAME', 12: 'U-USERNAME',\n",
    "    13: 'B-FAMILYNAME', 14: 'I-FAMILYNAME', 15: 'L-FAMILYNAME', 16: 'U-FAMILYNAME',\n",
    "    17: 'B-PERSONALNAME', 18: 'I-PERSONALNAME', 19: 'L-PERSONALNAME', 20: 'U-PERSONALNAME',\n",
    "    21: 'B-PROFESSION', 22: 'I-PROFESSION', 23: 'L-PROFESSION', 24: 'U-PROFESSION',\n",
    "    25: 'B-ROOM', 26: 'I-ROOM', 27: 'L-ROOM', 28: 'U-ROOM',\n",
    "    29: 'B-DEPARTMENT', 30: 'I-DEPARTMENT', 31: 'L-DEPARTMENT', 32: 'U-DEPARTMENT',\n",
    "    33: 'B-HOSPITAL', 34: 'I-HOSPITAL', 35: 'L-HOSPITAL', 36: 'U-HOSPITAL',\n",
    "    37: 'B-ORGANIZATION', 38: 'I-ORGANIZATION', 39: 'L-ORGANIZATION', 40: 'U-ORGANIZATION',\n",
    "    41: 'B-STREET', 42: 'I-STREET', 43: 'L-STREET', 44: 'U-STREET',\n",
    "    45: 'B-CITY', 46: 'I-CITY', 47: 'L-CITY', 48: 'U-CITY',\n",
    "    49: 'B-DISTRICT', 50: 'I-DISTRICT', 51: 'L-DISTRICT', 52: 'U-DISTRICT',\n",
    "    53: 'B-COUNTY', 54: 'I-COUNTY', 55: 'L-COUNTY', 56: 'U-COUNTY',\n",
    "    57: 'B-STATE', 58: 'I-STATE', 59: 'L-STATE', 60: 'U-STATE',\n",
    "    61: 'B-COUNTRY', 62: 'I-COUNTRY', 63: 'L-COUNTRY', 64: 'U-COUNTRY',\n",
    "    65: 'B-ZIP', 66: 'I-ZIP', 67: 'L-ZIP', 68: 'U-ZIP',\n",
    "    69: 'B-LOCATION-OTHER', 70: 'I-LOCATION-OTHER', 71: 'L-LOCATION-OTHER', 72: 'U-LOCATION-OTHER',\n",
    "    73: 'B-AGE', 74: 'I-AGE', 75: 'L-AGE', 76: 'U-AGE',\n",
    "    77: 'B-DATE', 78: 'I-DATE', 79: 'L-DATE', 80: 'U-DATE',\n",
    "    81: 'B-TIME', 82: 'I-TIME', 83: 'L-TIME', 84: 'U-TIME',\n",
    "    85: 'B-DURATION', 86: 'I-DURATION', 87: 'L-DURATION', 88: 'U-DURATION',\n",
    "    89: 'B-SET', 90: 'I-SET', 91: 'L-SET', 92: 'U-SET',\n",
    "    93: 'B-PHONE', 94: 'I-PHONE', 95: 'L-PHONE', 96: 'U-PHONE',\n",
    "    97: 'B-FAX', 98: 'I-FAX', 99: 'L-FAX', 100: 'U-FAX',\n",
    "    101: 'B-EMAIL', 102: 'I-EMAIL', 103: 'L-EMAIL', 104: 'U-EMAIL',\n",
    "    105: 'B-URL', 106: 'I-URL', 107: 'L-URL', 108: 'U-URL',\n",
    "    109: 'B-IPADDRESS', 110: 'I-IPADDRESS', 111: 'L-IPADDRESS', 112: 'U-IPADDRESS',\n",
    "    113: 'B-SOCIAL_SECURITY_NUMBER', 114: 'I-SOCIAL_SECURITY_NUMBER', 115: 'L-SOCIAL_SECURITY_NUMBER', 116: 'U-SOCIAL_SECURITY_NUMBER',\n",
    "    117: 'B-MEDICAL_RECORD_NUMBER', 118: 'I-MEDICAL_RECORD_NUMBER', 119: 'L-MEDICAL_RECORD_NUMBER', 120: 'U-MEDICAL_RECORD_NUMBER',\n",
    "    121: 'B-HEALTH_PLAN_NUMBER', 122: 'I-HEALTH_PLAN_NUMBER', 123: 'L-HEALTH_PLAN_NUMBER', 124: 'U-HEALTH_PLAN_NUMBER',\n",
    "    125: 'B-ACCOUNT_NUMBER', 126: 'I-ACCOUNT_NUMBER', 127: 'L-ACCOUNT_NUMBER', 128: 'U-ACCOUNT_NUMBER',\n",
    "    129: 'B-LICENSE_NUMBER', 130: 'I-LICENSE_NUMBER', 131: 'L-LICENSE_NUMBER', 132: 'U-LICENSE_NUMBER',\n",
    "    133: 'B-VEHICLE_ID', 134: 'I-VEHICLE_ID', 135: 'L-VEHICLE_ID', 136: 'U-VEHICLE_ID',\n",
    "    137: 'B-DEVICE_ID', 138: 'I-DEVICE_ID', 139: 'L-DEVICE_ID', 140: 'U-DEVICE_ID',\n",
    "    141: 'B-BIOMETRIC_ID', 142: 'I-BIOMETRIC_ID', 143: 'L-BIOMETRIC_ID', 144: 'U-BIOMETRIC_ID',\n",
    "    145: 'B-ID_NUMBER', 146: 'I-ID_NUMBER', 147: 'L-ID_NUMBER', 148: 'U-ID_NUMBER',\n",
    "    149: 'B-OTHER', 150: 'I-OTHER', 151: 'L-OTHER', 152: 'U-OTHER'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ab871afee70d4e2d9175b22cc5792b15",
      "2f737e699c3f4ad3817d0f90e3e83ae4",
      "57ee560aa4ca419d98084e8b0de9bb87",
      "625b9b4a9ee04ed3b53dfb2c1b1fabaa",
      "81ef4bf4932e4ed7bb247c179a2e7701",
      "fdef6e6b55e44f9cb346d9b3ba4e0c7c",
      "804969991550430e9a88cda8f5a5766c",
      "c77297715d324b2b9ad72ffff7dd14bd",
      "4aa90a4afd6c451b85fbbcf2461cd445",
      "c0fc8a30f7e44c039b8edab87ba4fc78",
      "045c2e8d7da0469ab15547772c097ea1"
     ]
    },
    "id": "Bc_nZ8Xsa9Kh",
    "outputId": "409288e5-4b13-4cf9-e7b2-652c18cb020e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab871afee70d4e2d9175b22cc5792b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import XLMRobertaForTokenClassification\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch.nn.functional as F # Import F\n",
    "\n",
    "\n",
    "\n",
    "from transformers import XLMRobertaForTokenClassification, AutoConfig\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"FacebookAI/xlm-roberta-large-finetuned-conll03-english\"\n",
    "config = AutoConfig.from_pretrained(model_name, num_labels=len( label_map ), token=access_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b34zuFfoZF-h"
   },
   "source": [
    "# **資料準備**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNoaYnyPZo0c"
   },
   "outputs": [],
   "source": [
    "def Caculate_Wav_File_Times( inputs ) :\n",
    "\n",
    "        read = inputs\n",
    "\n",
    "        dict_times = {}\n",
    "        for line in read:\n",
    "            line = line.strip()\n",
    "            line_split = line.split('\\t')\n",
    "\n",
    "            if line_split[0] not in dict_times :\n",
    "                dict_times[line_split[0]] = 1\n",
    "            else:\n",
    "                dict_times[line_split[0]] = dict_times[line_split[0]]  + 1\n",
    "\n",
    "        return dict_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS-G2EVIZslv"
   },
   "outputs": [],
   "source": [
    "# with open( \"/content/task2_answer.txt\", \"r\", encoding=\"utf-8\" ) as f :\n",
    "#   data = f.readlines()\n",
    "\n",
    "def Prepare_Task2_NER(data, is_big=False) :\n",
    "  data_times_dict = Caculate_Wav_File_Times( data )\n",
    "\n",
    "\n",
    "  data_list = {}\n",
    "  temp_dict = {}\n",
    "  temp_list = []\n",
    "\n",
    "  while data :\n",
    "\n",
    "    times = data_times_dict[data[0].split('\\t')[0]]\n",
    "\n",
    "    for i in range( times  ) :\n",
    "\n",
    "      line = data[i]\n",
    "\n",
    "\n",
    "      line = line.strip()\n",
    "      line_split = line.split(\"\\t\")\n",
    "\n",
    "      if is_big :\n",
    "        big_label = Change_small_label_to_big_label( line_split[1] )\n",
    "        temp_dict[ line_split[4] ] = big_label\n",
    "      else :\n",
    "        temp_dict[ line_split[4] ] = line_split[1]\n",
    "\n",
    "      temp_list.append( temp_dict )\n",
    "      temp_dict = {}\n",
    "\n",
    "    data_list[ data[0].split('\\t')[0] ] = temp_list\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    data = data[times:]\n",
    "\n",
    "\n",
    "  print(data_list)\n",
    "\n",
    "  return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGC3VhjUZvaU",
    "outputId": "e1250c9b-2ccc-4c09-81cb-a6cebd609aef"
   },
   "outputs": [],
   "source": [
    "#en\n",
    "with open( task2_train_data_path_txt, \"r\", encoding=\"utf-8\" ) as f :\n",
    "  data = f.readlines()\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# with open( \"/content/drive/MyDrive/AICUP_DATA/en-dataset/3_fold/hold_2/task2_answer_change.txt\", \"r\", encoding=\"utf-8\" ) as f :\n",
    "#   data = data + f.readlines()\n",
    "\n",
    "\n",
    "# with open( \"/content/drive/MyDrive/AICUP_DATA/en-dataset/3_fold/hold_3/task2_answer_change.txt\", \"r\", encoding=\"utf-8\" ) as f :\n",
    "#   data = data + f.readlines()\n",
    "\n",
    "\n",
    "\n",
    "# print(len(data))\n",
    "\n",
    "data_list = Prepare_Task2_NER( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txl9uCuMZwzJ",
    "outputId": "28687533-4dbc-479b-8bcf-c42bc02364ab"
   },
   "outputs": [],
   "source": [
    "#en\n",
    "with open( task2_val_data_path_txt, \"r\", encoding=\"utf-8\" ) as f :\n",
    "  val_data = f.readlines()\n",
    "\n",
    "print(len(val_data))\n",
    "\n",
    "\n",
    "val_data_list = Prepare_Task2_NER( val_data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8TioKK8bmHH",
    "outputId": "4904e960-cc7e-46c3-87d5-232f7448c239"
   },
   "outputs": [],
   "source": [
    "new_label2id= {v: k for k, v in label_map.items()}\n",
    "new_id2label = label_map\n",
    "\n",
    "# 更新配置\n",
    "config.id2label = new_id2label\n",
    "config.label2id = new_label2id\n",
    "\n",
    "# 打印新的 id2label 和 label2id\n",
    "print(\"新的 id2label:\", config.id2label)\n",
    "print(\"新的 label2id:\", config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRFZWNS7ZyVs"
   },
   "outputs": [],
   "source": [
    "def Prepare_Task1_NER( data, data_list):\n",
    "  train_data = []\n",
    "\n",
    "  for i in data:\n",
    "      # print( i )\n",
    "      line = i.strip()\n",
    "      line_split = line.split(\"\\t\")\n",
    "\n",
    "      name = line_split[0]\n",
    "      text = line_split[1]\n",
    "\n",
    "      tokens = tokenizer(text.strip(), return_offsets_mapping=True, return_tensors=\"pt\", truncation=True, add_special_tokens=True)\n",
    "      offsets = tokens[\"offset_mapping\"][0].tolist()\n",
    "      input_ids = tokens[\"input_ids\"][0].tolist()\n",
    "      token_texts = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "      # 初始化 label\n",
    "      label = [config.label2id[\"O\"]] * len(input_ids)\n",
    "      label[0] = -100\n",
    "      label[-1] = -100\n",
    "\n",
    "      input_ids = tokens[\"input_ids\"]\n",
    "      attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "\n",
    "      # print(f\"name: {name}\")\n",
    "      # print(f\"text: {text}\")\n",
    "      # print(f\"offsets: {offsets}\")\n",
    "      # print(tokens.tokens())\n",
    "\n",
    "\n",
    "      # 檢查是否有標註資料\n",
    "      if name not in data_list:\n",
    "          train_data.append({\n",
    "              \"input_ids\": input_ids[0].tolist(),\n",
    "              \"labels\": label,\n",
    "              \"attention_mask\": attention_mask[0].tolist()\n",
    "          })\n",
    "          continue\n",
    "\n",
    "      # 將標註合併為 (start, end, tag) 的格式\n",
    "      entities = []\n",
    "      used_indices = set()  # 防止重複使用相同文字\n",
    "      for ent in data_list[name]:\n",
    "          for word, tag in ent.items():\n",
    "              # 用 sliding window 尋找沒使用過的 word 位置\n",
    "              start = -1\n",
    "              for idx in range(len(text)):\n",
    "                  if idx in used_indices:\n",
    "                      continue\n",
    "                  if text[idx:idx+len(word)] == word:\n",
    "                      start = idx\n",
    "                      # 標記這些字元位置已經用過\n",
    "                      used_indices.update(range(start, start+len(word)))\n",
    "                      # print(used_indices)\n",
    "                      break\n",
    "              if start != -1:\n",
    "                  end = start + len(word)\n",
    "                  entities.append((start, end, tag))\n",
    "              else:\n",
    "                  print(f\"[未找到實體] name={name}, word='{word}', tag='{tag}'\")\n",
    "                  print(f\"→ 原始句子：{text}\")\n",
    "                  print(text[idx:idx+len(word)])\n",
    "\n",
    "      # print(f\"name: {name}\")\n",
    "      # print(f\"text: {text}\")\n",
    "      # print(f\"entities: {entities}\")\n",
    "      # print( offsets )\n",
    "\n",
    "      # 比對 offset 和 entity span，標註 label\n",
    "      for idx, (start, end) in enumerate(offsets):\n",
    "\n",
    "        if start == end:\n",
    "            continue\n",
    "        for ent_start, ent_end, tag in entities:\n",
    "            if start >= ent_start and end <= ent_end:\n",
    "                if ent_start == start and ent_end == end:  # 單 token 實體\n",
    "                    label[idx] = config.label2id[f\"U-{tag}\"]\n",
    "                    break\n",
    "                elif start == ent_start:\n",
    "                    label[idx] = config.label2id[f\"B-{tag}\"]\n",
    "                    break\n",
    "                elif end == ent_end:\n",
    "                    label[idx] = config.label2id[f\"L-{tag}\"]\n",
    "                    break\n",
    "                else:\n",
    "                    label[idx] = config.label2id[f\"I-{tag}\"]\n",
    "                    break\n",
    "\n",
    "      train_data.append({\n",
    "          \"input_ids\": input_ids[0].tolist(),\n",
    "          \"labels\": label,\n",
    "          \"attention_mask\": attention_mask[0].tolist()\n",
    "      })\n",
    "\n",
    "  return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4Fb9GZ5ZzsU",
    "outputId": "0081ddb5-8f9a-4356-b507-d968af3535ea"
   },
   "outputs": [],
   "source": [
    "#en\n",
    "with open( task1_train_data_path_txt, \"r\", encoding=\"utf-8\" ) as f :\n",
    "  data = f.readlines()\n",
    "\n",
    "print( len(data) )\n",
    "\n",
    "# with open( \"/content/drive/MyDrive/AICUP_DATA/en-dataset/3_fold/hold_2/task1_answer_change.txt\", \"r\", encoding=\"utf-8\" ) as f :\n",
    "#   data = data + f.readlines()\n",
    "\n",
    "# with open( \"/content/drive/MyDrive/AICUP_DATA/en-dataset/3_fold/hold_3/task1_answer_change.txt\", \"r\", encoding=\"utf-8\" ) as f :\n",
    "#   data = data + f.readlines()\n",
    "\n",
    "\n",
    "# print( len(data) )\n",
    "\n",
    "train_data = Prepare_Task1_NER( data, data_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8bfO38yZ080",
    "outputId": "92ac3aa5-32be-4074-ab9c-8537fcb74f0e"
   },
   "outputs": [],
   "source": [
    "#en\n",
    "with open( task1_val_data_path_txt, \"r\", encoding=\"utf-8\" ) as f :\n",
    "  val_data = f.readlines()\n",
    "\n",
    "print( len(val_data) )\n",
    "\n",
    "\n",
    "test_data = Prepare_Task1_NER( val_data, val_data_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYy87hcTZ2j1",
    "outputId": "54100a9e-f875-42a3-a800-d9249b5bd6a4"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vkc8bhRZZ3_O"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "data_train = Dataset.from_list(train_data)\n",
    "data_test = Dataset.from_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X82nu9DxZ5aZ",
    "outputId": "ef039edc-f7d1-4347-fbc9-ce32100d4014"
   },
   "outputs": [],
   "source": [
    "data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvE5nfp4Z7tu"
   },
   "source": [
    "# **TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsG8bRrgZ-8s",
    "outputId": "6e9fe8ed-99e5-405c-ea69-593fb18d5429"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(new_label2id),\n",
    "    id2label=new_id2label,\n",
    "    label2id=new_label2id,\n",
    "    ignore_mismatched_sizes=True   # 這行很重要！\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_u_to_bio_es(labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        if label.startswith('L-'):\n",
    "            new_labels.append('E-' + label[2:])\n",
    "        elif label.startswith('U-'):\n",
    "            new_labels.append('S-' + label[2:])\n",
    "        else:\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_Predict_Ner_BIOUL(pre):\n",
    "    answer_list = []\n",
    "    current_entity = None\n",
    "    current_word = \"\"\n",
    "    start_pos = None\n",
    "    end_pos = None\n",
    "\n",
    "    for dic in pre:\n",
    "        entity_type = dic['entity']\n",
    "        raw_word = dic['word']\n",
    "        word = raw_word.replace(\"▁\", \"\")\n",
    "        token_start = dic.get('start')\n",
    "        token_end = dic.get('end')\n",
    "        has_space = raw_word.startswith(\"▁\")\n",
    "\n",
    "        if entity_type.startswith(\"B-\"):\n",
    "            if current_entity and current_word:\n",
    "                answer_list.append({\n",
    "                    \"entity\": current_entity,\n",
    "                    \"word\": current_word,\n",
    "                    \"start\": start_pos,\n",
    "                    \"end\": end_pos\n",
    "                })\n",
    "            current_entity = entity_type.replace(\"B-\", \"\")\n",
    "            current_word = word\n",
    "            start_pos = token_start\n",
    "            end_pos = token_end\n",
    "\n",
    "        elif entity_type.startswith(\"I-\"):\n",
    "            ent = entity_type.replace(\"I-\", \"\")\n",
    "            if current_entity == ent:\n",
    "                if has_space:\n",
    "                    current_word += \" \" + word\n",
    "                else:\n",
    "                    current_word += word\n",
    "                end_pos = token_end\n",
    "            else:\n",
    "                if current_entity and current_word:\n",
    "                    answer_list.append({\n",
    "                        \"entity\": current_entity,\n",
    "                        \"word\": current_word,\n",
    "                        \"start\": start_pos,\n",
    "                        \"end\": end_pos\n",
    "                    })\n",
    "                current_entity = ent\n",
    "                current_word = word\n",
    "                start_pos = token_start\n",
    "                end_pos = token_end\n",
    "\n",
    "        elif entity_type.startswith(\"L-\"):\n",
    "            ent = entity_type.replace(\"L-\", \"\")\n",
    "            if current_entity == ent:\n",
    "                if has_space:\n",
    "                    current_word += \" \" + word\n",
    "                else:\n",
    "                    current_word += word\n",
    "                end_pos = token_end\n",
    "                answer_list.append({\n",
    "                    \"entity\": current_entity,\n",
    "                    \"word\": current_word,\n",
    "                    \"start\": start_pos,\n",
    "                    \"end\": end_pos\n",
    "                })\n",
    "                current_entity = None\n",
    "                current_word = \"\"\n",
    "                start_pos = None\n",
    "                end_pos = None\n",
    "            else:\n",
    "                # 如果之前的 entity 沒接上，當作獨立實體處理\n",
    "                answer_list.append({\n",
    "                    \"entity\": ent,\n",
    "                    \"word\": word,\n",
    "                    \"start\": token_start,\n",
    "                    \"end\": token_end\n",
    "                })\n",
    "                current_entity = None\n",
    "                current_word = \"\"\n",
    "                start_pos = None\n",
    "                end_pos = None\n",
    "\n",
    "        elif entity_type.startswith(\"U-\"):\n",
    "            ent = entity_type.replace(\"U-\", \"\")\n",
    "            answer_list.append({\n",
    "                \"entity\": ent,\n",
    "                \"word\": word,\n",
    "                \"start\": token_start,\n",
    "                \"end\": token_end\n",
    "            })\n",
    "\n",
    "            current_entity = None\n",
    "            current_word = \"\"\n",
    "            start_pos = None\n",
    "            end_pos = None\n",
    "\n",
    "        else:  # O\n",
    "            if current_entity and current_word:\n",
    "                answer_list.append({\n",
    "                    \"entity\": current_entity,\n",
    "                    \"word\": current_word,\n",
    "                    \"start\": start_pos,\n",
    "                    \"end\": end_pos\n",
    "                })\n",
    "            current_entity = None\n",
    "            current_word = \"\"\n",
    "            start_pos = None\n",
    "            end_pos = None\n",
    "\n",
    "    # 收尾\n",
    "    if current_entity and current_word:\n",
    "        answer_list.append({\n",
    "            \"entity\": current_entity,\n",
    "            \"word\": current_word,\n",
    "            \"start\": start_pos,\n",
    "            \"end\": end_pos\n",
    "        })\n",
    "\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level2_entities_normal(model, tokenizer, sentence, label_map):\n",
    "    device = next(model.parameters()).device  # 取得 model 裝置\n",
    "\n",
    "    # 1. Tokenize with offsets\n",
    "    encoding = tokenizer(sentence, return_tensors=\"pt\", return_offsets_mapping=True, truncation=True)\n",
    "    input_ids = encoding[\"input_ids\"].to(device)          # 放到 GPU\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)  # 放到 GPU\n",
    "    offsets = encoding[\"offset_mapping\"][0].tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu())  # token ids 放 CPU 才能用 tokenizer\n",
    "\n",
    "    # 2. Model forward\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, seq_len, num_labels]\n",
    "\n",
    "    preds = torch.argmax(logits, dim=2)[0].cpu().numpy()  # 預測結果放回 CPU\n",
    "\n",
    "    results = []\n",
    "    for idx, (pred_id, offset) in enumerate(zip(preds, offsets)):\n",
    "        token_id = input_ids[0, idx].item()\n",
    "\n",
    "        # 跳過特殊 token 或無效 offset\n",
    "        if token_id in [tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]:\n",
    "            continue\n",
    "\n",
    "        start, end = offset\n",
    "        entity = label_map.get(pred_id, \"O\")\n",
    "\n",
    "        if entity != \"O\":\n",
    "            probs = torch.softmax(logits[0, idx], dim=0)\n",
    "            score = probs[pred_id].item()\n",
    "\n",
    "            results.append({\n",
    "                \"entity\": entity,\n",
    "                \"score\": np.float32(score),\n",
    "                \"index\": idx,\n",
    "                \"word\": tokens[idx],  # 更準確\n",
    "                \"start\": start,\n",
    "                \"end\": end\n",
    "            })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_overlap(pred_start, pred_end, gt_start, gt_end):\n",
    "    \"\"\"計算兩個時間區間的重疊長度\"\"\"\n",
    "    overlap_start = max(pred_start, gt_start)\n",
    "    overlap_end = min(pred_end, gt_end)\n",
    "    overlap = max(0, overlap_end - overlap_start)\n",
    "    return overlap\n",
    "\n",
    "def evaluate_task2( ground_truth_file, model, tokenizer ) :\n",
    "\n",
    "\n",
    "\n",
    "    answer = \"\"\n",
    "\n",
    "    for text in val_data :\n",
    "\n",
    "      answer_list = []\n",
    "\n",
    "      text_split = text.strip().split(\"\\t\")\n",
    "      name = text_split[0]\n",
    "      text = text_split[1]\n",
    "\n",
    "      pre = get_level2_entities_normal(model, tokenizer, text, label_map)\n",
    "      if len(pre) != 0:\n",
    "        answer_list = Process_Predict_Ner_BIOUL(pre)\n",
    "\n",
    "      for i in answer_list:\n",
    "        answer += f\"{name}\\t{i['entity']}\\t{i['start']}\\t{i['end']}\\t{i['word']}\\n\"\n",
    "\n",
    "    prediction_file = \"model_eval.txt\"\n",
    "    with open( prediction_file, \"w\", encoding=\"utf-8\") as f:\n",
    "      f.write(answer)\n",
    "\n",
    "\n",
    "    # 讀取預測和真實標籤數據\n",
    "    import csv\n",
    "    pred_df = pd.read_csv(\n",
    "          prediction_file,\n",
    "          sep='\\t',\n",
    "          header=None,\n",
    "          names=['id', 'type', 'start', 'end', 'content'],\n",
    "          quoting=csv.QUOTE_NONE,        # 不解析引號\n",
    "          encoding='utf-8',              # 或試 utf-8-sig\n",
    "          on_bad_lines='skip',           # 跳過爛行\n",
    "          engine='python'                # 更寬容的 parser\n",
    "      )\n",
    "    gt_df = pd.read_csv(ground_truth_file, sep='\\t', header=None,\n",
    "                       names=['id', 'type', 'start', 'end', 'content'])\n",
    "\n",
    "    # 獲取所有獨特的SHI類型\n",
    "    all_types = sorted(set(gt_df['type'].unique()) | set(pred_df['type'].unique()))\n",
    "\n",
    "    # 初始化每種類型的指標\n",
    "    metrics = {shi_type: {'tp': 0, 'fp': 0, 'fn': 0} for shi_type in all_types}\n",
    "\n",
    "    # 按音頻ID分組處理\n",
    "    unique_ids = sorted(set(gt_df['id'].unique()) | set(pred_df['id'].unique()))\n",
    "\n",
    "    for audio_id in unique_ids:\n",
    "        gt_records = gt_df[gt_df['id'] == audio_id].copy()\n",
    "        pred_records = pred_df[pred_df['id'] == audio_id].copy()\n",
    "\n",
    "        # 初始化匹配矩陣來追蹤已處理的預測和真實標籤\n",
    "        gt_matched = [False] * len(gt_records)\n",
    "        pred_matched = [False] * len(pred_records)\n",
    "\n",
    "        # 計算True Positives和部分False Positives/False Negatives\n",
    "        for i, pred_row in enumerate(pred_records.itertuples()):\n",
    "            pred_type = pred_row.type\n",
    "            pred_start = pred_row.start\n",
    "            pred_end = pred_row.end\n",
    "            pred_duration = pred_end - pred_start\n",
    "\n",
    "            best_overlap = 0\n",
    "            best_gt_idx = -1\n",
    "\n",
    "            # 找到與當前預測重疊最大的真實標籤\n",
    "            for j, gt_row in enumerate(gt_records.itertuples()):\n",
    "                if gt_row.type != pred_type:\n",
    "                    continue\n",
    "\n",
    "                overlap = calculate_overlap(pred_start, pred_end, gt_row.start, gt_row.end)\n",
    "                if overlap > best_overlap:\n",
    "                    best_overlap = overlap\n",
    "                    best_gt_idx = j\n",
    "\n",
    "            if best_gt_idx >= 0:  # 找到部分匹配\n",
    "                gt_row = gt_records.iloc[best_gt_idx]\n",
    "                gt_duration = gt_row.end - gt_row.start\n",
    "\n",
    "                # 計算 True Positive\n",
    "                metrics[pred_type]['tp'] += best_overlap\n",
    "\n",
    "                # 計算 False Positive (對於部分匹配，類型相同)\n",
    "                metrics[pred_type]['fp'] += pred_duration - best_overlap\n",
    "\n",
    "                # 計算 False Negative (對於部分匹配，類型相同)\n",
    "                metrics[pred_type]['fn'] += gt_duration - best_overlap\n",
    "\n",
    "                # 標記已處理\n",
    "                gt_matched[best_gt_idx] = True\n",
    "                pred_matched[i] = True\n",
    "            else:\n",
    "                # 完全不匹配或者類型不同：整個預測為False Positive\n",
    "                metrics[pred_type]['fp'] += pred_duration\n",
    "\n",
    "        # 處理未匹配的真實標籤 (False Negatives)\n",
    "        for j, matched in enumerate(gt_matched):\n",
    "            if not matched:\n",
    "                gt_row = gt_records.iloc[j]\n",
    "                gt_type = gt_row.type\n",
    "                gt_duration = gt_row.end - gt_row.start\n",
    "                metrics[gt_type]['fn'] += gt_duration\n",
    "\n",
    "        # 處理與類型不同的預測 (False Positives)\n",
    "        for i, (matched, pred_row) in enumerate(zip(pred_matched, pred_records.itertuples())):\n",
    "            if matched:\n",
    "                continue\n",
    "\n",
    "            # 檢查是否有與其他類型匹配\n",
    "            pred_type = pred_row.type\n",
    "            pred_start = pred_row.start\n",
    "            pred_end = pred_row.end\n",
    "            pred_duration = pred_end - pred_start\n",
    "\n",
    "            for gt_row in gt_records.itertuples():\n",
    "                if gt_row.type == pred_type:\n",
    "                    continue  # 已在之前的步驟中處理過\n",
    "\n",
    "                overlap = calculate_overlap(pred_start, pred_end, gt_row.start, gt_row.end)\n",
    "                if overlap > 0:\n",
    "                    # 類型不匹配但時間重疊：整個預測為False Positive\n",
    "                    metrics[pred_type]['fp'] += pred_duration\n",
    "                    break\n",
    "\n",
    "    # 計算每種類型的Precision, Recall和F1\n",
    "    f1_scores = []\n",
    "    for shi_type in all_types:\n",
    "        m = metrics[shi_type]\n",
    "        precision = m['tp'] / (m['tp'] + m['fp']) if (m['tp'] + m['fp']) > 0 else 0\n",
    "        recall = m['tp'] / (m['tp'] + m['fn']) if (m['tp'] + m['fn']) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # print(f\"類型 {shi_type}:\")\n",
    "        # print(f\"  Precision: {precision:.4f}\")\n",
    "        # print(f\"  Recall: {recall:.4f}\")\n",
    "        # print(f\"  F1: {f1:.4f}\")\n",
    "        # print(f\"  TP: {m['tp']:.2f}, FP: {m['fp']:.2f}, FN: {m['fn']:.2f}\")\n",
    "        # print()\n",
    "\n",
    "    # 計算宏平均F1\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    # print(f\"Macro-Average F1: {macro_f1:.4f}\")\n",
    "\n",
    "    return macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class CharBasedEvaluationCallback(TrainerCallback):\n",
    "    def __init__(self, task2_path, tokenizer):\n",
    "        self.task2_path = task2_path\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "\n",
    "        macro_f1 = evaluate_task2(self.task2_path, model, self.tokenizer)\n",
    "\n",
    "        print(f\"[Char-based Evaluation after epoch {state.epoch}]\")\n",
    "        print(\"Macro-F1:\", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LspQztfOaBoW"
   },
   "outputs": [],
   "source": [
    "class FGM:\n",
    "    def __init__(self, model, epsilon=1.0):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, emb_name='embeddings.word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = self.epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='embeddings.word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name and name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww4SNKc7aE48"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class TrainerWithFGM(Trainer):\n",
    "    def __init__(self, *args, fgm=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fgm = fgm\n",
    "\n",
    "    def training_step(self, model, inputs, num_items):  # ← 加上 num_items\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        # 原始 loss\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "        loss.backward()\n",
    "\n",
    "        # 對抗訓練\n",
    "        if self.fgm is not None:\n",
    "            self.fgm.attack()\n",
    "            adv_loss = self.compute_loss(model, inputs)\n",
    "            adv_loss.backward()\n",
    "            self.fgm.restore()\n",
    "\n",
    "        return loss.detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jCu7NnqUaHBX",
    "outputId": "44154bc2-e113-45bc-96ba-c4a8a73bccb3"
   },
   "outputs": [],
   "source": [
    "# 假設你已經有 model 和 tokenizer\n",
    "\n",
    "# ✅ 建立 Trainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_first_step=True,\n",
    "    logging_dir=model_logging_dir,\n",
    "    learning_rate=3e-5,                     # 微幅調高（視情況）3e-5\n",
    "    num_train_epochs=20,                   # 避免一次就設 50\n",
    "    weight_decay=0.03,                     # 適當正則化 0.03\n",
    "    per_device_eval_batch_size=64,\n",
    "\n",
    ")\n",
    "\n",
    "task2_path = answer_val_data_path_txt\n",
    "\n",
    "fgm = FGM(model)\n",
    "\n",
    "trainer = TrainerWithFGM(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_test,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[CharBasedEvaluationCallback(task2_path, tokenizer)],\n",
    "    fgm=fgm,  # ✅ 加入這裡\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045c2e8d7da0469ab15547772c097ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f737e699c3f4ad3817d0f90e3e83ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdef6e6b55e44f9cb346d9b3ba4e0c7c",
      "placeholder": "​",
      "style": "IPY_MODEL_804969991550430e9a88cda8f5a5766c",
      "value": "config.json: 100%"
     }
    },
    "4aa90a4afd6c451b85fbbcf2461cd445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57ee560aa4ca419d98084e8b0de9bb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c77297715d324b2b9ad72ffff7dd14bd",
      "max": 852,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4aa90a4afd6c451b85fbbcf2461cd445",
      "value": 852
     }
    },
    "625b9b4a9ee04ed3b53dfb2c1b1fabaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0fc8a30f7e44c039b8edab87ba4fc78",
      "placeholder": "​",
      "style": "IPY_MODEL_045c2e8d7da0469ab15547772c097ea1",
      "value": " 852/852 [00:00&lt;00:00, 105kB/s]"
     }
    },
    "804969991550430e9a88cda8f5a5766c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81ef4bf4932e4ed7bb247c179a2e7701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab871afee70d4e2d9175b22cc5792b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f737e699c3f4ad3817d0f90e3e83ae4",
       "IPY_MODEL_57ee560aa4ca419d98084e8b0de9bb87",
       "IPY_MODEL_625b9b4a9ee04ed3b53dfb2c1b1fabaa"
      ],
      "layout": "IPY_MODEL_81ef4bf4932e4ed7bb247c179a2e7701"
     }
    },
    "c0fc8a30f7e44c039b8edab87ba4fc78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c77297715d324b2b9ad72ffff7dd14bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdef6e6b55e44f9cb346d9b3ba4e0c7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
