{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_predict_all_result_path:  ./checkpoints/NER_model\n",
      "whisper_timestamp_word_level_path:  ./checkpoints/NER_model\n",
      "whisper_timestamp_char_level_path:  ./checkpoints/NER_model\n",
      "char_level_timestamp_task2_NER_result_path:  \n",
      "word_level_timestamp_task2_NER_result_path:  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config_argument = json.load(f)\n",
    "\n",
    "model_predict_all_result_path_txt = config_argument[\"model_predict_all_result_path_txt\"]\n",
    "\n",
    "whisper_timestamp_word_level_path_json = config_argument[\"whisper_timestamp_word_level_path_json\"]\n",
    "whisper_timestamp_char_level_path_json = config_argument[\"whisper_timestamp_char_level_path_json\"]\n",
    "\n",
    "word_level_timestamp_task2_NER_result_path_txt = config_argument[\"word_level_timestamp_task2_NER_result_path_txt\"]\n",
    "char_level_timestamp_task2_NER_result_path_txt = config_argument[\"char_level_timestamp_task2_NER_result_path_txt\"]\n",
    "\n",
    "\n",
    "print( \"model_predict_all_result_path_txt: \", model_predict_all_result_path_txt )\n",
    "print( \"whisper_timestamp_word_level_path_json: \", whisper_timestamp_word_level_path_json )\n",
    "print( \"whisper_timestamp_char_level_path_json: \", whisper_timestamp_char_level_path_json )\n",
    "print( \"char_level_timestamp_task2_NER_result_path_txt: \", char_level_timestamp_task2_NER_result_path_txt )\n",
    "print( \"word_level_timestamp_task2_NER_result_path_txt: \", word_level_timestamp_task2_NER_result_path_txt )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrGdPhH7KYd2"
   },
   "source": [
    "word_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2FK6Ge6KTnx"
   },
   "outputs": [],
   "source": [
    "def align_ner_with_whisper(ner_entities, whisper_words):\n",
    "    results = []\n",
    "\n",
    "    for ent in ner_entities:\n",
    "        ent_start = ent[\"start\"]\n",
    "        ent_end = ent[\"end\"]\n",
    "        name = ent[\"name\"]\n",
    "\n",
    "        # print(ent_start, ent_end)\n",
    "        matched_words = []\n",
    "\n",
    "        for word in whisper_words[str(name)]:\n",
    "            w_start = word[\"char_start\"]\n",
    "            w_end = word[\"char_end\"]\n",
    "\n",
    "            # if int(w_start) <= int(ent_start) <= int(w_end):   # 方法1\n",
    "            #     matched_words.append(word)\n",
    "\n",
    "            #檢查是否重疊（部分包含）\n",
    "            if not (int(w_end) <= int(ent_start) or int(w_start) >= int(ent_end)): # 方法2\n",
    "                matched_words.append(word)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(matched_words)\n",
    "\n",
    "\n",
    "        if matched_words:\n",
    "            ts_start = matched_words[0]['start_time']\n",
    "            ts_end = matched_words[-1]['end_time']\n",
    "            results.append({\n",
    "                \"entity\": ent[\"word\"],\n",
    "                \"start_time\": ts_start,\n",
    "                \"end_time\": ts_end\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"entity\": ent[\"word\"],\n",
    "                \"start_time\": None,\n",
    "                \"end_time\": None\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BY964r1XKOmn",
    "outputId": "58d716e5-2e2b-4c1d-c289-970ffa9559ea"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open( whisper_timestamp_word_level_path_json, \"r\" ) as f:\n",
    "    wisper_word = json.load(f)\n",
    "\n",
    "with open( model_predict_all_result_path_txt, \"r\" ) as f:\n",
    "  data = f.readlines()\n",
    "\n",
    "\n",
    "pre_dict = {}\n",
    "pre_list = []\n",
    "\n",
    "for line in data :\n",
    "\n",
    "  line = line.strip()\n",
    "  line_split = line.split(\"\\t\")\n",
    "\n",
    "\n",
    "  pre_dict[\"name\"] = line_split[0]\n",
    "  pre_dict[\"type\"] = line_split[1]\n",
    "  pre_dict[\"start\"] = line_split[2]\n",
    "  pre_dict[\"end\"] = line_split[3]\n",
    "  pre_dict[\"word\"] = line_split[4]\n",
    "\n",
    "  pre_list.append(pre_dict)\n",
    "  pre_dict = {}\n",
    "\n",
    "# print(pre_list)\n",
    "\n",
    "# print( pre_list[0] )\n",
    "# print(wisper_word[\"271.wav\"])\n",
    "\n",
    "# print(wisper_word)\n",
    "\n",
    "results = align_ner_with_whisper(pre_list, wisper_word)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XY-L-rlNOVm"
   },
   "outputs": [],
   "source": [
    "with open( word_level_timestamp_task2_NER_result_path_txt , \"w\") as f:\n",
    "    for index, r in enumerate(pre_list):\n",
    "        start_time = float(results[index]['start_time'])\n",
    "        end_time = float(results[index]['end_time'])\n",
    "        f.write(f\"{r['name']}\\t{r['type']}\\t{start_time:.3f}\\t{end_time:.3f}\\t{results[index]['entity']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5DO9KTrQmSb"
   },
   "source": [
    "char_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WVXtuM0TCiM"
   },
   "outputs": [],
   "source": [
    "def align_char_level_ner_with_whisper(ner_entity, whisper_chars):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ner in ner_entity:\n",
    "\n",
    "      name = ner[\"name\"]\n",
    "\n",
    "      ent_start = int(ner[\"start\"])\n",
    "      ent_end = int(ner[\"end\"])\n",
    "\n",
    "      # print(ent_start, ent_end)\n",
    "\n",
    "\n",
    "\n",
    "      matched_chars = [\n",
    "          c for c in whisper_chars[name]\n",
    "          if ent_start <= c[\"index\"] < ent_end\n",
    "      ]\n",
    "\n",
    "      if matched_chars:\n",
    "          ts_start = matched_chars[0][\"start\"]\n",
    "          ts_end = matched_chars[-1][\"end\"]\n",
    "          result.append( {\n",
    "              \"entity\": ner[\"word\"],\n",
    "              \"start_time\": ts_start,\n",
    "              \"end_time\": ts_end\n",
    "          } )\n",
    "      else:\n",
    "          result.append( {\n",
    "              \"entity\": ner[\"word\"],\n",
    "              \"start_time\": None,\n",
    "              \"end_time\": None\n",
    "          } )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNPLzV8gQldH",
    "outputId": "3e1ebf4d-1b30-45e9-8c5f-c800f5f50dbe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open( whisper_timestamp_char_level_path_json, \"r\") as f:\n",
    "    wisper_word = json.load(f)\n",
    "\n",
    "with open( model_predict_all_result_path_txt, \"r\") as f:\n",
    "  data = f.readlines()\n",
    "\n",
    "\n",
    "pre_dict = {}\n",
    "pre_list = []\n",
    "\n",
    "for line in data :\n",
    "\n",
    "  line = line.strip()\n",
    "  line_split = line.split(\"\\t\")\n",
    "\n",
    "\n",
    "  pre_dict[\"name\"] = line_split[0]\n",
    "  pre_dict[\"type\"] = line_split[1]\n",
    "  pre_dict[\"start\"] = line_split[2]\n",
    "  pre_dict[\"end\"] = line_split[3]\n",
    "  pre_dict[\"word\"] = line_split[4]\n",
    "\n",
    "  pre_list.append(pre_dict)\n",
    "  pre_dict = {}\n",
    "\n",
    "# print(pre_list)\n",
    "\n",
    "# print( pre_list[0] )\n",
    "# print(wisper_word[\"271\"])\n",
    "\n",
    "\n",
    "result = align_char_level_ner_with_whisper(pre_list, wisper_word)\n",
    "\n",
    "print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwFgx-7yU29E"
   },
   "outputs": [],
   "source": [
    "with open( char_level_timestamp_task2_NER_result_path_txt, \"w\") as f:\n",
    "\n",
    "  for index, r in enumerate(pre_list):\n",
    "    f.write(f\"{r['name']}\\t{r['type']}\\t{result[index]['start_time']}\\t{result[index]['end_time']}\\t{result[index]['entity']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
