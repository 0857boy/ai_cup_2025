{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeHwxLlCV7xV",
        "outputId": "686d8157-a31b-4202-b9b7-bfe23122ed50"
      },
      "outputs": [],
      "source": [
        "!pip install  whisperx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhwwrktGcxQ2",
        "outputId": "9f8c1686-97fd-4d0d-a45d-23d898d6fa0c"
      },
      "outputs": [],
      "source": [
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5haw0bRhUAV",
        "outputId": "0644734f-1ad3-4dc7-9057-3940584038df"
      },
      "outputs": [],
      "source": [
        "!git clone https://huggingface.co/Systran/faster-whisper-large-v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvEe8tHMgGp7",
        "outputId": "ff62bf5b-6d35-495c-ed3e-1d38a6619353"
      },
      "outputs": [],
      "source": [
        "!git lfs pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfYkwfF4wESG",
        "outputId": "c80143d5-3d19-4cc5-aaca-9e2ad7b63685"
      },
      "outputs": [],
      "source": [
        "!apt-get install libcudnn8 libcudnn8-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"config.json\", \"r\") as f:\n",
        "    config_argument = json.load(f)\n",
        "\n",
        "audio_file_path = config_argument[\"audio_file_path\"]\n",
        "\n",
        "\n",
        "print( \"audio_file_path: \", audio_file_path )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cEveWWl4gRY",
        "outputId": "c118ca67-63cc-411a-f6b4-69e492f34cd4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "result = []\n",
        "\n",
        "# å¤šå€‹è³‡æ–™å¤¾è·¯å¾‘\n",
        "folder_paths = [\n",
        "    audio_file_path,\n",
        "    # å¯ç¹¼çºŒåŠ å…¥å…¶ä»–è³‡æ–™å¤¾è·¯å¾‘\n",
        "]\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    print(f'\\nğŸ“‚ æª”æ¡ˆä¾†è‡ªè³‡æ–™å¤¾ï¼š{folder_path}')\n",
        "\n",
        "    # è®€å‡ºæ‰€æœ‰ .wav æª”æ¡ˆ\n",
        "    wav_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.wav')]\n",
        "\n",
        "    # æ ¹æ“šæª”åæ•¸å­—æ’åº\n",
        "    try:\n",
        "        wav_files_sorted = sorted(wav_files, key=lambda x: int(os.path.splitext(x)[0]))\n",
        "    except ValueError:\n",
        "        print(\"âš ï¸ æª”åç„¡æ³•è½‰ç‚ºæ•¸å­—ï¼Œè·³éæ­¤è³‡æ–™å¤¾\")\n",
        "        continue\n",
        "\n",
        "    # å°å‡ºå®Œæ•´è·¯å¾‘\n",
        "    for wav_file in wav_files_sorted:\n",
        "        full_path = os.path.join(folder_path, wav_file)\n",
        "        print(full_path)\n",
        "        result.append(full_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hADkH5TP8cpF"
      },
      "source": [
        "**åŸºç¤ASR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT_ZZdR8B6BW",
        "outputId": "2689316f-b1b3-4fad-9836-760063ed3eee"
      },
      "outputs": [],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "compute_type = \"float16\"\n",
        "answer = \"\"\n",
        "\n",
        "model = whisperx.load_model(\"./faster-whisper-large-v3\", device, compute_type=compute_type)\n",
        "\n",
        "\n",
        "for wav_file in result:\n",
        "\n",
        "  name = wav_file.split(\"/\")[-1].replace(\".wav\", \"\")\n",
        "\n",
        "  audio = whisperx.load_audio( wav_file )\n",
        "  result = model.transcribe(audio)\n",
        "\n",
        "  result[\"segments\"][0][\"text\"] = result[\"segments\"][0][\"text\"].strip()\n",
        "\n",
        "  answer = answer + name + \"\\t\" + result[\"segments\"][0][\"text\"] + \"\\n\"\n",
        "\n",
        "  print( result[\"segments\"][0][\"text\"] )\n",
        "\n",
        "with open(\"./val_asr_1.txt\", \"w\") as f:\n",
        "    f.write(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2VykBEoSbIV"
      },
      "source": [
        "**æ”¹é€²ASR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Ikbll9BhSapp",
        "outputId": "035eb831-8daf-481a-f51d-baa70d3422b3"
      },
      "outputs": [],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "compute_type = \"float16\"\n",
        "answer = \"\"\n",
        "\n",
        "\n",
        "\n",
        "for wav_file in result:\n",
        "    name = wav_file.split(\"/\")[-1].replace(\".wav\", \"\")\n",
        "    audio = whisperx.load_audio(wav_file)\n",
        "    result = model.transcribe(audio)  # è‹¥ç¢ºå®šèªè¨€å¯æŒ‡å®š\n",
        "\n",
        "    text = \" \".join([seg[\"text\"].strip() for seg in result[\"segments\"]])\n",
        "\n",
        "    answer += name + \"\\t\" + text + \"\\n\"\n",
        "\n",
        "    print(text)\n",
        "\n",
        "with open(\"./val_asr_2.txt\", \"w\") as f:\n",
        "    f.write(answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZWlfU3IB4Gs"
      },
      "source": [
        "timestaamp index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w44y-c0fdKiY",
        "outputId": "3957f409-7e16-4ecb-b77a-9de50bf9b5d4"
      },
      "outputs": [],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "whisperx.load_model\n",
        "\n",
        "device = \"cuda\"\n",
        "compute_type = \"float16\"\n",
        "data_dic = {}\n",
        "\n",
        "model = whisperx.load_model(\"./faster-whisper-large-v3\", device, compute_type=compute_type)\n",
        "\n",
        "\n",
        "for wav_file in result:\n",
        "\n",
        "  print(wav_file)\n",
        "\n",
        "  name = wav_file.split(\"/\")[-1].replace(\".wav\", \"\")\n",
        "\n",
        "  audio = whisperx.load_audio( wav_file )\n",
        "  result = model.transcribe(audio)\n",
        "\n",
        "  result[\"segments\"][0][\"text\"] = result[\"segments\"][0][\"text\"].strip()\n",
        "\n",
        "  # print(result[\"segments\"]) # before alignment\n",
        "  print( result[\"segments\"][0][\"text\"] )\n",
        "\n",
        "  model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "  result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=True)\n",
        "\n",
        "  print(result[\"segments\"]) # after alignment\n",
        "\n",
        "\n",
        "  index = 0\n",
        "  data_list = []\n",
        "  temp_dic = {}\n",
        "\n",
        "\n",
        "  for i in result[\"segments\"]:\n",
        "      for c in i.get(\"chars\", []):  # å®‰å…¨å–å‡º charsï¼Œé¿å… KeyError\n",
        "\n",
        "          temp_dic = {\n",
        "              \"index\": index,\n",
        "              \"char\": c.get(\"char\", \"\"),  # é è¨­ç©ºå­—å…ƒ\n",
        "              \"start\": c.get(\"start\"),    # å¦‚æœæ²’æœ‰æœƒæ˜¯ None\n",
        "              \"end\": c.get(\"end\")\n",
        "          }\n",
        "\n",
        "          data_list.append(temp_dic)\n",
        "          index += 1\n",
        "\n",
        "  data_dic[name] = data_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdg9IJCQ48OS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"./whisperx_char_level.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data_dic, f, indent=2, ensure_ascii=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
