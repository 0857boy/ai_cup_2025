# Task 1: èªéŸ³è­˜åˆ¥ (ASR) - é†«ç—…èªéŸ³æ•æ„Ÿå€‹äººè³‡æ–™è¾¨è­˜ç«¶è³½

## ğŸ“– ä»»å‹™æ¦‚è¿°

Task 1 å°ˆæ³¨æ–¼èªéŸ³è­˜åˆ¥ (Automatic Speech Recognition, ASR)ï¼Œå°‡é†«ç™‚å°è©±èªéŸ³æª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—ä¸¦è¼¸å‡ºè½‰éŒ„çµæœã€‚æœ¬ä»»å‹™æä¾›äº†å¤šç¨®å¯¦ä½œæ–¹æ¡ˆï¼Œå¾åŸºç¤çš„ Whisper åˆ°é€²éšçš„ WhisperX + Ollama æ•´åˆæ–¹æ¡ˆã€‚

## ğŸ¯ ä»»å‹™ç›®æ¨™

- å°‡é†«ç™‚èªéŸ³å°è©±è½‰æ›ç‚ºæº–ç¢ºçš„æ–‡å­—è½‰éŒ„
- æä¾›å­—ç¬¦ç´šæ™‚é–“æˆ³å°é½ŠåŠŸèƒ½
- æ”¯æ´ä¸­æ–‡ï¼ˆç¹ç°¡è½‰æ›ï¼‰èªéŸ³è­˜åˆ¥
- æ•´åˆ NER æ¨™è¨»åŠŸèƒ½ä»¥è­˜åˆ¥æ•æ„Ÿå¥åº·è³‡è¨Š

## ğŸ“ æª”æ¡ˆçµæ§‹

```
task1/
â”œâ”€â”€ README.md                    # æœ¬æª”æ¡ˆ - Task 1 è©³ç´°èªªæ˜
â”œâ”€â”€ ollama_qwen_whis.py         # ä¸»è¦è™•ç†è…³æœ¬ (WhisperX + Ollama NER)
â”œâ”€â”€ whisper_large_v3.py         # åŸºç¤ Whisper ç‰ˆæœ¬
â””â”€â”€ Whisperx.ipynb              # WhisperX é€²éšç‰ˆæœ¬ (Jupyter Notebook)
```

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### 1. WhisperX + Ollama æ•´åˆæ–¹æ¡ˆ (`ollama_qwen_whis.py`)

**ç‰¹é»ï¼š**
- ä½¿ç”¨ WhisperX Large-v3 é€²è¡Œé«˜ç²¾åº¦èªéŸ³è­˜åˆ¥
- æ•´åˆ Ollama Qwen3 é€²è¡Œä¸­æ–‡ NER æ¨™è¨»
- æ”¯æ´å­—ç¬¦ç´šæ™‚é–“æˆ³å°é½Š
- è‡ªå‹•ç°¡ç¹è½‰æ›
- æ”¯æ´å¤šèªè¨€æª¢æ¸¬

**æ”¯æ´çš„ NER æ¨™ç±¤ï¼š**
```python
NER_LABELS = [
    "PATIENT", "DOCTOR", "FAMILYNAME", "PERSONALNAME",
    "PROFESSION", "ROOM", "DEPARTMENT", "HOSPITAL", 
    "STREET", "CITY", "DISTRICT", "COUNTY", "STATE", "COUNTRY", 
    "AGE", "DATE", "TIME", "DURATION", "SET", "PHONE"
]
```

### 2. åŸºç¤ Whisper ç‰ˆæœ¬ (`whisper_large_v3.py`)

**ç‰¹é»ï¼š**
- ä½¿ç”¨ whisper-timestamped å¥—ä»¶
- æ”¯æ´ Whisper Large-v3 æ¨¡å‹
- åŸºç¤èªéŸ³è½‰æ–‡å­—åŠŸèƒ½
- é©åˆå¿«é€ŸåŸå‹é–‹ç™¼

### 3. WhisperX é€²éšç‰ˆæœ¬ (`Whisperx.ipynb`)

**ç‰¹é»ï¼š**
- Jupyter Notebook äº’å‹•å¼ç’°å¢ƒ
- æ”¯æ´æ‰¹æ¬¡è™•ç†å¤šå€‹è³‡æ–™å¤¾
- æä¾›å­—ç¬¦ç´šæ™‚é–“æˆ³ç´¢å¼•
- æ”¯æ´å°é½Šå¾Œçš„ç²¾ç¢ºæ™‚é–“æ¨™è¨˜

## ğŸ› ï¸ ç’°å¢ƒè¨­ç½®

### ç³»çµ±éœ€æ±‚
- **Python**: 3.8+
- **GPU**: å»ºè­° 8GB+ VRAM (CUDA 11.0+)
- **è¨˜æ†¶é«”**: å»ºè­° 16GB+ RAM

### ä¾è³´å¥—ä»¶å®‰è£

```bash
# åŸºç¤å¥—ä»¶
pip install torch torchaudio transformers

# WhisperX ç›¸é—œ
pip install whisperx
pip install whisper-timestamped

# æ–‡å­—è™•ç†
pip install opencc-python-reimplemented
pip install numpy pandas tqdm

# Ollama (æœ¬åœ° LLM)
# è«‹è‡³ https://ollama.ai ä¸‹è¼‰ä¸¦å®‰è£
ollama pull qwen3:8b
```

## ğŸ“‹ ä½¿ç”¨èªªæ˜

### æ–¹æ¡ˆä¸€ï¼šWhisperX + Ollama æ•´åˆæ–¹æ¡ˆï¼ˆæ¨è–¦ï¼‰

```bash
# åŸºæœ¬ä½¿ç”¨
python ollama_qwen_whis.py

# æŒ‡å®šè¼¸å…¥è³‡æ–™å¤¾å’Œè¼¸å‡ºæª”æ¡ˆ
python ollama_qwen_whis.py --input_dir "audio_files/" --task1_output "asr_results.txt"
```

**è¼¸å‡ºæ ¼å¼ï¼š**
- `task1_output.txt`: æª”æ¡ˆåç¨± + è½‰éŒ„æ–‡å­—
- `task2_output.txt`: NER æ¨™è¨»çµæœ

**ç¯„ä¾‹è¼¸å‡ºï¼š**
```
1001	æ‚£è€…ç‹å°æ˜ä»Šå¤©ä¾†çœ‹è¨ºï¼Œä¸»è¨´æ˜¯èƒ¸ç—›ã€‚
1002	é†«å¸«å»ºè­°åšå¿ƒé›»åœ–æª¢æŸ¥ï¼Œæ™‚é–“å®‰æ’åœ¨ä¸‹åˆ2é»ã€‚
```

### æ–¹æ¡ˆäºŒï¼šåŸºç¤ Whisper ç‰ˆæœ¬

```python
import whisper_timestamped as whisper
import os

# è¼‰å…¥æ¨¡å‹
model = whisper.load_model("whisper-large-v3", device="cuda")

# è™•ç†å–®ä¸€æª”æ¡ˆ
audio_path = "audio_file.wav"
audio = whisper.load_audio(audio_path)
result = whisper.transcribe(model, audio, language="zh")

print(result["text"])
```

### æ–¹æ¡ˆä¸‰ï¼šWhisperX é€²éšç‰ˆæœ¬

é–‹å•Ÿ `Whisperx.ipynb` ä¸¦åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š

1. **å®‰è£ä¾è³´**
```bash
!pip install whisperx
!git lfs install
!git clone https://huggingface.co/Systran/faster-whisper-large-v3
```

2. **è¼‰å…¥æ¨¡å‹ä¸¦è™•ç†**
```python
import whisperx

device = "cuda"
compute_type = "float16"

model = whisperx.load_model("/content/faster-whisper-large-v3", device, compute_type=compute_type)

# è™•ç†éŸ³é »æª”æ¡ˆ
audio = whisperx.load_audio(wav_file)
result = model.transcribe(audio)
```

3. **æ™‚é–“æˆ³å°é½Š**
```python
model_a, metadata = whisperx.load_align_model(language_code=result["language"], device=device)
result = whisperx.align(result["segments"], model_a, metadata, audio, device, return_char_alignments=True)
```

## âš™ï¸ é…ç½®é¸é …

### WhisperX é…ç½®

```python
class WhisperXProcessor:
    def __init__(self, 
                 model_name="large-v3",      # æ¨¡å‹ç‰ˆæœ¬
                 device="cuda",              # è¨ˆç®—è¨­å‚™
                 compute_type="float16",     # è¨ˆç®—ç²¾åº¦
                 language=None):             # èªè¨€è¨­å®š (None=è‡ªå‹•æª¢æ¸¬)
```

### æ€§èƒ½å„ªåŒ–è¨­å®š

```python
# å•Ÿç”¨ TensorFloat-32 åŠ é€Ÿ
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# æ··åˆç²¾åº¦è¨ˆç®—
compute_type = "float16"  # GPU
compute_type = "int8"     # CPU
```

## ğŸ“Š æ€§èƒ½æŒ‡æ¨™

### è™•ç†é€Ÿåº¦
- **GPU (RTX 4090)**: 10-20x å¯¦æ™‚è™•ç†é€Ÿåº¦
- **CPU**: 0.5-1x å¯¦æ™‚è™•ç†é€Ÿåº¦

### æº–ç¢ºåº¦
- **ä¸­æ–‡èªéŸ³è­˜åˆ¥**: WER < 15%
- **è‹±æ–‡èªéŸ³è­˜åˆ¥**: WER < 10%
- **å¤šèªè¨€æ··åˆ**: WER < 20%

### è¨˜æ†¶é«”ä½¿ç”¨
- **WhisperX Large-v3**: ~6GB VRAM
- **åŸºç¤ Whisper**: ~4GB VRAM
- **CPU æ¨¡å¼**: ~8GB RAM

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **CUDA è¨˜æ†¶é«”ä¸è¶³**
```bash
# è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨è¼ƒå°çš„æ¨¡å‹æˆ– CPU æ¨¡å¼
model_name = "medium"  # æˆ– "small", "base"
device = "cpu"
compute_type = "int8"
```

2. **Ollama é€£ç·šå¤±æ•—**
```bash
# ç¢ºèª Ollama æœå‹™é‹è¡Œ
ollama list
ollama run qwen3:8b

# æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰
ollama show qwen3:8b
```

3. **éŸ³é »æ ¼å¼ä¸æ”¯æ´**
```bash
# è½‰æ›ç‚ºæ”¯æ´æ ¼å¼ (16kHz WAV)
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```

4. **ç°¡ç¹è½‰æ›å•é¡Œ**
```python
from opencc import OpenCC
converter = OpenCC('s2t')  # ç°¡è½‰ç¹
text = converter.convert("ç®€ä½“ä¸­æ–‡")
```

### éŒ¯èª¤è¨Šæ¯å°ç…§

| éŒ¯èª¤è¨Šæ¯ | åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|----------|------|----------|
| `CUDA out of memory` | GPU è¨˜æ†¶é«”ä¸è¶³ | æ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨ CPU |
| `Model not found` | æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ | é‡æ–°ä¸‹è¼‰æ¨¡å‹ |
| `Audio format not supported` | éŸ³é »æ ¼å¼å•é¡Œ | è½‰æ›ç‚º WAV æ ¼å¼ |
| `Connection refused` | Ollama æœå‹™æœªå•Ÿå‹• | å•Ÿå‹• Ollama æœå‹™ |

## ğŸ›ï¸ é€²éšé…ç½®

### è‡ªè¨‚ NER æç¤ºè©

```python
ollama_prompt = f"""ä½ æ˜¯ä¸€å€‹ä¸­æ–‡é†«ç™‚å°ˆç”¨NERæ¨™è¨»å·¥å…·ï¼Œè«‹æ ¹æ“šä¸‹åˆ—åˆ†é¡å¾ä¸­æ–‡å¥å­ä¸­æå–å‘½åå¯¦é«”ã€‚

é¡åˆ¥å¦‚ä¸‹ï¼š
{', '.join(NER_LABELS)}

è¼¸å‡ºæ ¼å¼ç‚ºï¼š<é¡åˆ¥>\\t<å¯¦é«”æ–‡å­—>ï¼Œæ¯è¡Œä¸€å€‹å¯¦é«”ã€‚è‹¥ç„¡å¯¦é«”ï¼Œè«‹å›ç­” "ç„¡å¯¦é«”"ã€‚

ç‰¹æ®Šè¦å‰‡ï¼š
- PATIENT, DOCTOR, PERSONALNAME, FAMILYNAMEéƒ½ç®—æ˜¯NAMEçš„ç¯„ç–‡
- åå­—å¾ŒåŠ ä¸Šç¸½ã€é†«å¸«ã€é†«ç”Ÿéƒ½ä»£è¡¨æ˜¯DOCTOR  
- ä»£ç¨±éƒ½ä¸èƒ½ç®—æ˜¯NAMEçš„ç¯„ç–‡ï¼Œå“¥å“¥ã€çˆ¸çˆ¸ã€å¤§å“¥ã€è€å¤§éƒ½ä¸æ˜¯NAME
- HOSPITALä¸€å®šè¦æ˜¯é†«é™¢åå­—ï¼Œåªæœ‰é†«é™¢å…©å€‹å­—æˆ–è‘—æœ¬é™¢éƒ½ä¸æ˜¯HOSPITAL
- ROOMç‚ºåºŠä½è³‡è¨Šï¼Œè€Œä¸æ˜¯æˆ¿é–“åï¼Œæ‰‹è¡“å®¤ã€æ€¥è¨ºå®¤éƒ½ä¸æ˜¯ROOM

ä»¥ä¸‹æ˜¯å¥å­ï¼š{text}
è«‹æ¨™è¨»æ‰€æœ‰å¯¦é«”ã€‚
"""
```

### æ‰¹æ¬¡è™•ç†é…ç½®

```python
# è™•ç†å¤šå€‹è³‡æ–™å¤¾
folder_paths = [
    '/path/to/folder1',
    '/path/to/folder2',
    '/path/to/folder3'
]

# ä¸¦è¡Œè™•ç†è¨­å®š
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=4) as executor:
    # ä¸¦è¡Œè™•ç†éŸ³é »æª”æ¡ˆ
    pass
```

## ğŸ“ˆ è©•ä¼°æŒ‡æ¨™

### èªéŸ³è­˜åˆ¥è©•ä¼°
- **å­—ç¬¦éŒ¯èª¤ç‡ (CER)**: å­—ç¬¦ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **è©éŒ¯èª¤ç‡ (WER)**: è©ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **BLEU åˆ†æ•¸**: ç¿»è­¯å“è³ªè©•ä¼°

### NER æ¨™è¨»è©•ä¼°
- **ç²¾ç¢ºç‡ (Precision)**: æ­£ç¢ºè­˜åˆ¥çš„å¯¦é«” / ç¸½è­˜åˆ¥å¯¦é«”
- **å¬å›ç‡ (Recall)**: æ­£ç¢ºè­˜åˆ¥çš„å¯¦é«” / ç¸½çœŸå¯¦å¯¦é«”  
- **F1 åˆ†æ•¸**: ç²¾ç¢ºç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡

## ğŸ”— ç›¸é—œè³‡æº

### æ¨¡å‹è³‡æº
- [WhisperX GitHub](https://github.com/m-bain/whisperX)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [Ollama å®˜ç¶²](https://ollama.ai/)

### æŠ€è¡“æ–‡æª”
- [Whisper æ¨¡å‹ä»‹ç´¹](https://openai.com/research/whisper)
- [WhisperX è«–æ–‡](https://arxiv.org/abs/2303.00747)
- [èªéŸ³è­˜åˆ¥è©•ä¼°æŒ‡æ¨™](https://en.wikipedia.org/wiki/Word_error_rate)

## ğŸ’¡ æœ€ä½³å¯¦è¸

1. **éŸ³é »é è™•ç†**ï¼šä½¿ç”¨é è™•ç†æ¨¡çµ„é€²è¡ŒéŸ³é »å¢å¼·
2. **æ‰¹æ¬¡è™•ç†**ï¼šåˆç†è¨­å®šæ‰¹æ¬¡å¤§å°é¿å…è¨˜æ†¶é«”æº¢å‡º
3. **æ¨¡å‹é¸æ“‡**ï¼šæ ¹æ“šç¡¬é«”è³‡æºé¸æ“‡é©ç•¶çš„æ¨¡å‹å¤§å°
4. **çµæœé©—è­‰**ï¼šäººå·¥æª¢æŸ¥é—œéµçµæœç¢ºä¿å“è³ª
5. **éŒ¯èª¤è™•ç†**ï¼šå¯¦ä½œå®Œæ•´çš„ç•°å¸¸è™•ç†æ©Ÿåˆ¶

## ğŸ“ æ›´æ–°æ—¥èªŒ

- **v1.0.0**: åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æ´åŸºç¤ Whisper èªéŸ³è­˜åˆ¥
- **v1.1.0**: åŠ å…¥ WhisperX æ”¯æ´ï¼Œæå‡è­˜åˆ¥ç²¾åº¦
- **v1.2.0**: æ•´åˆ Ollama NER åŠŸèƒ½ï¼Œå®Œæ•´çš„ç«¯åˆ°ç«¯è§£æ±ºæ–¹æ¡ˆ
- **v1.3.0**: åŠ å…¥å­—ç¬¦ç´šæ™‚é–“æˆ³å°é½Šï¼Œæ”¯æ´å¤šèªè¨€æª¢æ¸¬
