# AI Cup 2025 - é†«ç—…èªéŸ³æ•æ„Ÿå€‹äººè³‡æ–™è¾¨è­˜ç«¶è³½

## ğŸ† ç«¶è³½æ¦‚è¿°

æœ¬å°ˆæ¡ˆç‚º AI Cup 2025 é†«ç—…èªéŸ³æ•æ„Ÿå€‹äººè³‡æ–™è¾¨è­˜ç«¶è³½çš„å®Œæ•´è§£æ±ºæ–¹æ¡ˆï¼Œå°ˆæ³¨æ–¼å¾é†«ç™‚å°è©±ä¸­è­˜åˆ¥ä¸¦ä¿è­·æ‚£è€…éš±ç§è³‡è¨Šï¼Œæ¶µè“‹èªéŸ³è½‰æ–‡å­— (ASR)ã€æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥ (SHI Detection) ä»¥åŠæ™‚é–“æˆ³å°é½Šç­‰å¤šé …å…ˆé€²æŠ€è¡“ã€‚

### ğŸ¯ ä»»å‹™ç›®æ¨™

- **Task 1**: èªéŸ³è­˜åˆ¥ (ASR) - å°‡é†«ç™‚å°è©±èªéŸ³æª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—ä¸¦è¼¸å‡ºè½‰éŒ„çµæœ
- **Task 2**: æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥ (SHI Detection) - å¾è½‰éŒ„æ–‡å­—ä¸­è­˜åˆ¥é†«ç™‚æ•æ„Ÿå¥åº·è³‡è¨Šä¸¦æä¾›æ™‚é–“æˆ³å°é½Šï¼Œä»¥ä¿è­·æ‚£è€…éš±ç§

### ğŸ… ä¸»è¦æˆæœ

- **èªéŸ³è­˜åˆ¥**: ä½¿ç”¨ WhisperX Large-v3 + Ollama Qwen3 å¯¦ç¾é«˜ç²¾åº¦ ASR
- **æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥**: åŸºæ–¼ XLM-RoBERTa + CRF + FGM å°æŠ—è¨“ç·´é”åˆ°å„ªç•°çš„æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥æ•ˆèƒ½
- **éŸ³é »è™•ç†**: å…ˆé€²çš„ Transformer ç¥ç¶“ç¶²çµ¡éŸ³é »å¢å¼·ç³»çµ±
- **éš±ç§ä¿è­·**: æ™ºèƒ½æ•æ„Ÿå¥åº·è³‡è¨Šæª¢æ¸¬èˆ‡æ™‚é–“æˆ³å°é½ŠæŠ€è¡“

## ğŸ“ å°ˆæ¡ˆæ¶æ§‹

```
ai_cup_2025/
â”œâ”€â”€ README.md                    # å°ˆæ¡ˆç¸½è¦½ (æœ¬æª”æ¡ˆ)
â”œâ”€â”€ preprocess/                  # éŸ³é »é è™•ç†æ¨¡çµ„
â”‚   â”œâ”€â”€ audio_prepare.py         # å…ˆé€²éŸ³é »è™•ç† (Transformer å¢å¼·)
â”‚   â”œâ”€â”€ audio_prepare(task1).py  # è¼•é‡ç´šéŸ³é »è™•ç†
â”‚   â”œâ”€â”€ split_and_check_k_hold_with_test.py  # æ•¸æ“šé›†åˆ†å‰²
â”‚   â””â”€â”€ README.md                # é è™•ç†æ¨¡çµ„èªªæ˜
â”œâ”€â”€ task1/                       # Task 1: èªéŸ³è­˜åˆ¥
â”‚   â”œâ”€â”€ ollama_qwen_whis.py      # ä¸»è¦è™•ç†è…³æœ¬ (WhisperX + Ollama)
â”‚   â”œâ”€â”€ whisper_large_v3.ipynb   # Whisper åŸºç¤ç‰ˆæœ¬
â”‚   â”œâ”€â”€ Whisperx.ipynb           # WhisperX é€²éšç‰ˆæœ¬
â”‚   â””â”€â”€ README.md                # Task 1 è©³ç´°èªªæ˜
â””â”€â”€ task2/                       # Task 2: æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥
    â”œâ”€â”€ NER_CRF_FGM_BIO.ipynb    # CRF + FGM è¨“ç·´ä¸»ç¨‹å¼
    â”œâ”€â”€ predict_all.ipynb        # å¤šæ¨¡å‹é æ¸¬èˆ‡é›†æˆ
    â”œâ”€â”€ Insert_timestamp.ipynb   # æ™‚é–“æˆ³å°é½Šè™•ç†
    â””â”€â”€ README.md                # Task 2 è©³ç´°èªªæ˜
```

## ğŸš€ æ ¸å¿ƒæŠ€è¡“ç‰¹é»

### ğŸµ éŸ³é »é è™•ç† (preprocess/)
- **Transformer ç¥ç¶“ç¶²çµ¡å¢å¼·**: åŸºæ–¼æ·±åº¦å­¸ç¿’çš„éŸ³é »é™å™ªèˆ‡å¢å¼·
- **å¿ƒç†è²å­¸å»ºæ¨¡**: åŸºæ–¼äººé¡è½è¦ºæ„ŸçŸ¥çš„æ™ºèƒ½éŸ³é »è™•ç†
- **GPU æ··åˆç²¾åº¦è¨ˆç®—**: æ”¯æ´ CUDA åŠ é€Ÿï¼Œå¤§å¹…æå‡è™•ç†é€Ÿåº¦
- **K-fold æ•¸æ“šåˆ†å‰²**: ä½¿ç”¨ MultilabelStratifiedKFold ç¢ºä¿æ¨™ç±¤åˆ†å¸ƒå¹³è¡¡

### ğŸ—£ï¸ èªéŸ³è­˜åˆ¥ (task1/)
- **WhisperX Large-v3**: æ¥­ç•Œé ˜å…ˆçš„èªéŸ³è­˜åˆ¥æ¨¡å‹
- **Ollama Qwen3**: æœ¬åœ°éƒ¨ç½²çš„ä¸­æ–‡ NER æ¨¡å‹
- **å­—ç¬¦ç´šæ™‚é–“æˆ³**: ç²¾ç¢ºåˆ°å­—ç¬¦ç´šåˆ¥çš„æ™‚é–“å°é½Š
- **ç°¡ç¹è½‰æ›**: è‡ªå‹•è™•ç†ç¹ç°¡é«”ä¸­æ–‡è½‰æ›

### ğŸ·ï¸ æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥ (task2/)
- **XLM-RoBERTa Large**: å¤šèªè¨€é è¨“ç·´æ¨¡å‹
- **CRF (æ¢ä»¶éš¨æ©Ÿå ´)**: ç¢ºä¿åºåˆ—æ¨™è¨»ä¸€è‡´æ€§
- **FGM å°æŠ—è¨“ç·´**: æå‡æ¨¡å‹é­¯æ£’æ€§
- **éš±ç§ä¿è­·**: å°ˆæ³¨æ–¼è­˜åˆ¥é†«ç™‚å°è©±ä¸­çš„æ•æ„Ÿå¥åº·è³‡è¨Š (SHI)

## ğŸ› ï¸ ç’°å¢ƒè¨­ç½®

### ç³»çµ±éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Windows 10/11, Linux, macOS
- **Python**: 3.8+
- **GPU**: å»ºè­° 8GB+ VRAM (æ”¯æ´ CUDA 11.0+)
- **è¨˜æ†¶é«”**: å»ºè­° 16GB+ RAM

### æ ¸å¿ƒä¾è³´å¥—ä»¶

```bash
# åŸºç¤å¥—ä»¶
pip install torch torchaudio transformers
pip install numpy pandas tqdm scikit-learn

# éŸ³é »è™•ç†
pip install librosa soundfile whisperx
pip install scipy psutil GPUtil

# NER ç›¸é—œ
pip install torchcrf pytorch-crf
pip install datasets opencc-python-reimplemented

# æ•¸æ“šè™•ç†
pip install iterstrat  # å¤šæ¨™ç±¤åˆ†å±¤åˆ†å‰²

# Ollama (æœ¬åœ° LLM)
# è«‹è‡³ https://ollama.ai ä¸‹è¼‰ä¸¦å®‰è£
ollama pull qwen3:8b
```

### å¿«é€Ÿå®‰è£

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/your-repo/ai_cup_2025.git
cd ai_cup_2025

# å®‰è£ä¾è³´ (å»ºè­°ä½¿ç”¨è™›æ“¬ç’°å¢ƒ)
pip install -r requirements.txt

# å®‰è£ Ollama æ¨¡å‹
ollama pull qwen3:8b
```

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿé–‹å§‹

### 1. éŸ³é »é è™•ç†

```bash
cd preprocess
python audio_prepare.py --input_dir "raw_audio/" --output_dir "processed_audio/"
```

### 2. Task 1: èªéŸ³è­˜åˆ¥

```bash
cd task1
python ollama_qwen_whis.py --input_dir "audio_files/" --task1_output "asr_results.txt"
```

### 3. Task 2: æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥

```bash
cd task2
# è¨“ç·´æ¨¡å‹
éœ€è¦å…ˆè¨­å®šhuggling face access_tokenã€å„²å­˜æ¨¡å‹è·¯å¾‘
jupyter notebook NER_CRF_FGM_BIO.ipynb

# é æ¸¬çµæœ
éœ€è¦å…ˆè¨­å®šhuggling face access_tokenã€é æ¸¬æ¨¡å‹è·¯å¾‘
jupyter notebook Insert_timestamp.ipynb

### 4. æ•¸æ“šé›†åˆ†å‰²

```bash
cd preprocess
python split_and_check_k_hold_with_test.py
```

## ğŸ“Š å¯¦é©—çµæœèˆ‡æ•ˆèƒ½

### Task 1 (èªéŸ³è­˜åˆ¥)
- **æ¨¡å‹**: WhisperX Large-v3 + Ollama Qwen3
- **è™•ç†é€Ÿåº¦**: 10-20x å¯¦æ™‚è™•ç†é€Ÿåº¦ (GPU)
- **èªè¨€æ”¯æ´**: ä¸­æ–‡ (ç¹/ç°¡)ã€è‡ªå‹•èªè¨€æª¢æ¸¬
- **è¼¸å‡ºæ ¼å¼**: æª”æ¡ˆåç¨± + è½‰éŒ„æ–‡å­—

### Task 2 (æ•æ„Ÿå¥åº·è³‡è¨Šè­˜åˆ¥)
#### ğŸ“Š NER æ¨¡å‹çµ„åˆ F1-score æ¯”è¼ƒ

| ç·¨è™Ÿ | æ¨™è¨˜æ–¹å¼ | ä½¿ç”¨æŠ€è¡“              | F1-score | è¨“ç·´æ­¥æ•¸ |
|------|----------|------------------------|----------|----------|
| 1    | BIOU     | baseline               | 0.6856   | 812      |
| 2    | BIOU     | + FGM                  | 0.6698   | 1160     |
| 3    | BIOU     | + CRF                  | 0.7084   | 1276     |
| 4    | BIOU     | + focal loss           | 0.6791   | 1856     |
| 5    | BIOU     | + weight loss          | 0.6497   | 3248     |
| 6    | BIO      | baseline               | 0.6729   | 1044     |
| 7    | BIO      | + FGM                  | 0.6801   | 1624     |
| 8    | BIO      | + CRF                  | 0.7184   | 3016     |
| 9    | BIO      | + focal loss           | 0.7063   | 1508     |
| 10   | BIO      | + weight loss          | 0.6581   | 1856     |
| 11   | BIO      | + CRF + FGM            | **0.7256** | 2088     |

### æ”¯æ´çš„æ•æ„Ÿå¥åº·è³‡è¨Šé¡åˆ¥ (SHI - 20ç¨®)
- **äººç‰©è³‡è¨Š**: PATIENT, DOCTOR, FAMILYNAME, PERSONALNAME
- **è·æ¥­è³‡è¨Š**: PROFESSION
- **åœ°é»è³‡è¨Š**: ROOM, DEPARTMENT, HOSPITAL, STREET, CITY, DISTRICT, COUNTY, STATE, COUNTRY
- **æ™‚é–“è³‡è¨Š**: AGE, DATE, TIME, DURATION, SET
- **è¯çµ¡è³‡è¨Š**: PHONE

## ğŸ”§ é€²éšé…ç½®

### éŸ³é »è™•ç†é…ç½®

```python
# è‡ªå®šç¾©éŸ³é »è™•ç†é…ç½®
config = ProcessingConfig(
    sr=22050,                    # æ¡æ¨£ç‡
    n_fft=2048,                  # FFT çª—å£å¤§å°
    use_neural_enhancement=True,  # å•Ÿç”¨ç¥ç¶“ç¶²çµ¡å¢å¼·
    use_mixed_precision=True,     # æ··åˆç²¾åº¦è¨ˆç®—
    max_batch_size=16            # æ‰¹æ¬¡å¤§å°
)
```

### NER æ¨¡å‹é…ç½®

```python
# è¨“ç·´åƒæ•¸é…ç½®
training_args = TrainingArguments(
    output_dir="./ner_results",
    learning_rate=3e-5,
    num_train_epochs=40,
    per_device_train_batch_size=4,
    weight_decay=0.03
)
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **CUDA è¨˜æ†¶é«”ä¸è¶³**
   ```bash
   # è§£æ±ºæ–¹æ¡ˆï¼šæ¸›å°‘æ‰¹æ¬¡å¤§å°
   --per_device_batch_size=2
   # æˆ–å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»
   --gradient_checkpointing=True
   ```

2. **Ollama é€£ç·šå¤±æ•—**
   ```bash
   # ç¢ºèª Ollama æœå‹™é‹è¡Œ
   ollama list
   ollama run qwen3:8b
   ```

3. **éŸ³é »æ ¼å¼ä¸æ”¯æ´**
   ```bash
   # è½‰æ›ç‚ºæ”¯æ´æ ¼å¼
   ffmpeg -i input.mp3 -ar 16000 output.wav
   ```

### æ•ˆèƒ½å„ªåŒ–å»ºè­°

- **ä½¿ç”¨ GPU åŠ é€Ÿ**: ç¢ºä¿å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch
- **æ··åˆç²¾åº¦è¨“ç·´**: å•Ÿç”¨ AMP å¯ç¯€çœ 50% è¨˜æ†¶é«”
- **æ‰¹æ¬¡è™•ç†**: å¢åŠ æ‰¹æ¬¡å¤§å°å¯æå‡ GPU åˆ©ç”¨ç‡
- **æ¨¡å‹é‡åŒ–**: ä½¿ç”¨ INT8 é‡åŒ–æ¸›å°‘æ¨ç†æ™‚é–“

## ğŸ“ˆ è©•ä¼°æŒ‡æ¨™

### Task 1 è©•ä¼°
- **å­—ç¬¦éŒ¯èª¤ç‡ (CER)**: å­—ç¬¦ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **è©éŒ¯èª¤ç‡ (WER)**: è©ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **è™•ç†é€Ÿåº¦**: ç›¸å°æ–¼å¯¦æ™‚çš„è™•ç†å€é€Ÿ

### Task 2 è©•ä¼°
- **ç²¾ç¢ºç‡ (Precision)**: TP / (TP + FP)
- **å¬å›ç‡ (Recall)**: TP / (TP + FN)
- **F1 åˆ†æ•¸**: ç²¾ç¢ºç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡
- **å®å¹³å‡ F1**: æ‰€æœ‰ SHI é¡åˆ¥ F1 çš„å¹³å‡å€¼

## ğŸ”— ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡æª”
- [AI Cup 2025 å®˜ç¶²](https://www.aicup.tw/)
- [æ¯”è³½è¦å‰‡èˆ‡è©•åˆ†æ¨™æº–](https://www.codabench.org/competitions/4890/)

### æŠ€è¡“æ–‡æª”
- [WhisperX GitHub](https://github.com/m-bain/whisperX)
- [XLM-RoBERTa](https://huggingface.co/FacebookAI/xlm-roberta-large)
- [Ollama å®˜ç¶²](https://ollama.ai/)
- [TorchCRF](https://pytorch-crf.readthedocs.io/)

### å­¸è¡“è«–æ–‡
- [Whisper: Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)
- [XLM-RoBERTa: Unsupervised Cross-lingual Representation Learning](https://arxiv.org/abs/1911.02116)
- [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](https://repository.upenn.edu/cis_papers/159/)

## ğŸ“ æ›´æ–°æ—¥èªŒ

### v2.0.0 (2025-06-12)
- âœ¨ æ–°å¢ Transformer ç¥ç¶“ç¶²çµ¡éŸ³é »å¢å¼·
- âœ¨ æ•´åˆ WhisperX + Ollama å®Œæ•´èªéŸ³è­˜åˆ¥æµç¨‹
- âœ¨ å¯¦ç¾ CRF + FGM å°æŠ—è¨“ç·´ SHI è­˜åˆ¥æ¨¡å‹
- âœ¨ åŠ å…¥å¿ƒç†è²å­¸å»ºæ¨¡èˆ‡ GPU æ··åˆç²¾åº¦è¨ˆç®—
- ğŸ”§ å„ªåŒ–æ•¸æ“šé›†åˆ†å‰²èˆ‡ K-fold äº¤å‰é©—è­‰
- ğŸ“š å®Œå–„æŠ€è¡“æ–‡æª”èˆ‡ä½¿ç”¨èªªæ˜

### v1.0.0 (2025-05-01)
- ğŸ‰ å°ˆæ¡ˆåˆå§‹ç‰ˆæœ¬
- âœ¨ åŸºç¤éŸ³é »é è™•ç†åŠŸèƒ½
- âœ¨ Whisper èªéŸ³è­˜åˆ¥æ•´åˆ
- âœ¨ XLM-RoBERTa SHI è­˜åˆ¥æ¨¡å‹
- ğŸ“š åŸºç¤èªªæ˜æ–‡æª”

## æˆæ¬Š

æœ¬å°ˆæ¡ˆä¾ç…§ [GNU GPL v3](LICENSE) æ¢æ¬¾æˆæ¬Šã€‚  
è©³è¦‹ LICENSE æª”æ¡ˆä»¥å–å¾—å®Œæ•´æ¢æ¬¾ã€‚
