# AI Cup 2025 - é†«ç™‚èªéŸ³è­˜åˆ¥èˆ‡å‘½åå¯¦é«”è­˜åˆ¥ç«¶è³½

## ğŸ† ç«¶è³½æ¦‚è¿°

æœ¬å°ˆæ¡ˆç‚º AI Cup 2025 é†«ç™‚èªéŸ³è­˜åˆ¥èˆ‡å‘½åå¯¦é«”è­˜åˆ¥ç«¶è³½çš„å®Œæ•´è§£æ±ºæ–¹æ¡ˆï¼Œæ¶µè“‹èªéŸ³è½‰æ–‡å­— (ASR)ã€å‘½åå¯¦é«”è­˜åˆ¥ (NER) ä»¥åŠæ™‚é–“æˆ³å°é½Šç­‰å¤šé …å…ˆé€²æŠ€è¡“ã€‚

### ğŸ¯ ä»»å‹™ç›®æ¨™

- **Task 1**: èªéŸ³è­˜åˆ¥ (ASR) - å°‡é†«ç™‚èªéŸ³æª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—ä¸¦è¼¸å‡ºè½‰éŒ„çµæœ
- **Task 2**: å‘½åå¯¦é«”è­˜åˆ¥ (NER) - å¾è½‰éŒ„æ–‡å­—ä¸­è­˜åˆ¥é†«ç™‚ç›¸é—œå¯¦é«”ä¸¦æä¾›æ™‚é–“æˆ³å°é½Š

### ğŸ… ä¸»è¦æˆæœ

- **èªéŸ³è­˜åˆ¥**: ä½¿ç”¨ WhisperX Large-v3 + Ollama Qwen3 å¯¦ç¾é«˜ç²¾åº¦ ASR
- **å¯¦é«”è­˜åˆ¥**: åŸºæ–¼ XLM-RoBERTa + CRF + FGM å°æŠ—è¨“ç·´é”åˆ°å„ªç•°æ•ˆèƒ½
- **éŸ³é »è™•ç†**: å…ˆé€²çš„ Transformer ç¥ç¶“ç¶²çµ¡éŸ³é »å¢å¼·ç³»çµ±
- **æ•¸æ“šç®¡ç†**: æ™ºèƒ½ K-fold äº¤å‰é©—è­‰èˆ‡æ•¸æ“šé›†åˆ†å‰²å·¥å…·

## ğŸ“ å°ˆæ¡ˆæ¶æ§‹

```
ai_cup_2025/
â”œâ”€â”€ README.md                    # å°ˆæ¡ˆç¸½è¦½ (æœ¬æª”æ¡ˆ)
â”œâ”€â”€ preprocess/                  # éŸ³é »é è™•ç†æ¨¡çµ„
â”‚   â”œâ”€â”€ audio_prepare.py         # å…ˆé€²éŸ³é »è™•ç† (Transformer å¢å¼·)
â”‚   â”œâ”€â”€ audio_prepare(task1).py  # è¼•é‡ç´šéŸ³é »è™•ç†
â”‚   â”œâ”€â”€ split_and_check_k_hold_with_test.py  # æ•¸æ“šé›†åˆ†å‰²
â”‚   â””â”€â”€ README.md                # é è™•ç†æ¨¡çµ„èªªæ˜
â”œâ”€â”€ task1/                       # Task 1: èªéŸ³è­˜åˆ¥
â”‚   â”œâ”€â”€ ollama_qwen_whis.py      # ä¸»è¦è™•ç†è…³æœ¬ (WhisperX + Ollama)
â”‚   â”œâ”€â”€ whisper_large_v3.ipynb   # Whisper åŸºç¤ç‰ˆæœ¬
â”‚   â”œâ”€â”€ Whisperx.ipynb           # WhisperX é€²éšç‰ˆæœ¬
â”‚   â””â”€â”€ README.md                # Task 1 è©³ç´°èªªæ˜
â””â”€â”€ task2/                       # Task 2: å‘½åå¯¦é«”è­˜åˆ¥
    â”œâ”€â”€ NER_CRF_FGM_BIO.ipynb    # CRF + FGM è¨“ç·´ä¸»ç¨‹å¼
    â”œâ”€â”€ predict_all.ipynb        # å¤šæ¨¡å‹é æ¸¬èˆ‡é›†æˆ
    â”œâ”€â”€ Insert_timestamp.ipynb   # æ™‚é–“æˆ³å°é½Šè™•ç†
    â”œâ”€â”€ inference.py             # æ¨ç†è…³æœ¬
    â””â”€â”€ README.md                # Task 2 è©³ç´°èªªæ˜
```

## ğŸš€ æ ¸å¿ƒæŠ€è¡“ç‰¹é»

### ğŸµ éŸ³é »é è™•ç† (preprocess/)
- **Transformer ç¥ç¶“ç¶²çµ¡å¢å¼·**: åŸºæ–¼æ·±åº¦å­¸ç¿’çš„éŸ³é »é™å™ªèˆ‡å¢å¼·
- **å¿ƒç†è²å­¸å»ºæ¨¡**: åŸºæ–¼äººé¡è½è¦ºæ„ŸçŸ¥çš„æ™ºèƒ½éŸ³é »è™•ç†
- **GPU æ··åˆç²¾åº¦è¨ˆç®—**: æ”¯æ´ CUDA åŠ é€Ÿï¼Œå¤§å¹…æå‡è™•ç†é€Ÿåº¦
- **K-fold æ•¸æ“šåˆ†å‰²**: ä½¿ç”¨ MultilabelStratifiedKFold ç¢ºä¿æ¨™ç±¤åˆ†å¸ƒå¹³è¡¡

### ğŸ—£ï¸ èªéŸ³è­˜åˆ¥ (task1/)
- **WhisperX Large-v3**: æ¥­ç•Œé ˜å…ˆçš„èªéŸ³è­˜åˆ¥æ¨¡å‹
- **Ollama Qwen3**: æœ¬åœ°éƒ¨ç½²çš„ä¸­æ–‡ NER æ¨¡å‹
- **å­—ç¬¦ç´šæ™‚é–“æˆ³**: ç²¾ç¢ºåˆ°å­—ç¬¦ç´šåˆ¥çš„æ™‚é–“å°é½Š
- **ç°¡ç¹è½‰æ›**: è‡ªå‹•è™•ç†ç¹ç°¡é«”ä¸­æ–‡è½‰æ›

### ğŸ·ï¸ å‘½åå¯¦é«”è­˜åˆ¥ (task2/)
- **XLM-RoBERTa Large**: å¤šèªè¨€é è¨“ç·´æ¨¡å‹
- **CRF (æ¢ä»¶éš¨æ©Ÿå ´)**: ç¢ºä¿åºåˆ—æ¨™è¨»ä¸€è‡´æ€§
- **FGM å°æŠ—è¨“ç·´**: æå‡æ¨¡å‹é­¯æ£’æ€§
- **Focal Loss**: è™•ç†é¡åˆ¥ä¸å¹³è¡¡å•é¡Œ
- **éšå±¤å¼åˆ†é¡**: Level 1 + Level 2 é›™å±¤åˆ†é¡æ¶æ§‹

## ğŸ› ï¸ ç’°å¢ƒè¨­ç½®

### ç³»çµ±éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Windows 10/11, Linux, macOS
- **Python**: 3.8+
- **GPU**: å»ºè­° 8GB+ VRAM (æ”¯æ´ CUDA 11.0+)
- **è¨˜æ†¶é«”**: å»ºè­° 16GB+ RAM

### æ ¸å¿ƒä¾è³´å¥—ä»¶

```bash
# åŸºç¤å¥—ä»¶
pip install torch torchaudio transformers
pip install numpy pandas tqdm scikit-learn

# éŸ³é »è™•ç†
pip install librosa soundfile whisperx
pip install scipy psutil GPUtil

# NER ç›¸é—œ
pip install torchcrf pytorch-crf
pip install datasets opencc-python-reimplemented

# æ•¸æ“šè™•ç†
pip install iterstrat  # å¤šæ¨™ç±¤åˆ†å±¤åˆ†å‰²

# Ollama (æœ¬åœ° LLM)
# è«‹è‡³ https://ollama.ai ä¸‹è¼‰ä¸¦å®‰è£
ollama pull qwen3:8b
```

### å¿«é€Ÿå®‰è£

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/your-repo/ai_cup_2025.git
cd ai_cup_2025

# å®‰è£ä¾è³´ (å»ºè­°ä½¿ç”¨è™›æ“¬ç’°å¢ƒ)
pip install -r requirements.txt

# å®‰è£ Ollama æ¨¡å‹
ollama pull qwen3:8b
```

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿé–‹å§‹

### 1. éŸ³é »é è™•ç†

```bash
cd preprocess
python audio_prepare.py --input_dir "raw_audio/" --output_dir "processed_audio/"
```

### 2. Task 1: èªéŸ³è­˜åˆ¥

```bash
cd task1
python ollama_qwen_whis.py --input_dir "audio_files/" --task1_output "asr_results.txt"
```

### 3. Task 2: å‘½åå¯¦é«”è­˜åˆ¥

```bash
cd task2
# è¨“ç·´æ¨¡å‹
jupyter notebook NER_CRF_FGM_BIO.ipynb

# é æ¸¬çµæœ
python inference.py --model_dir "trained_model/" --input_file "asr_results.txt" --output_file "ner_results.txt"
```

### 4. æ•¸æ“šé›†åˆ†å‰²

```bash
cd preprocess
python split_and_check_k_hold_with_test.py
```

## ğŸ“Š å¯¦é©—çµæœèˆ‡æ•ˆèƒ½

### Task 1 (èªéŸ³è­˜åˆ¥)
- **æ¨¡å‹**: WhisperX Large-v3 + Ollama Qwen3
- **è™•ç†é€Ÿåº¦**: 10-20x å¯¦æ™‚è™•ç†é€Ÿåº¦ (GPU)
- **èªè¨€æ”¯æ´**: ä¸­æ–‡ (ç¹/ç°¡)ã€è‡ªå‹•èªè¨€æª¢æ¸¬
- **è¼¸å‡ºæ ¼å¼**: æª”æ¡ˆåç¨± + è½‰éŒ„æ–‡å­—

### Task 2 (å‘½åå¯¦é«”è­˜åˆ¥)
| æ¨¡å‹æ¶æ§‹ | Macro F1 | è¨“ç·´æ™‚é–“ | GPU è¨˜æ†¶é«” |
|----------|----------|----------|------------|
| XLM-RoBERTa | 0.8520 | 2h | 6GB |
| + CRF | 0.8687 | 2.5h | 7GB |
| + FGM | 0.8756 | 3h | 7GB |
| + Focal Loss | 0.8698 | 2.8h | 7GB |

### æ”¯æ´çš„å¯¦é«”é¡åˆ¥ (20ç¨®)
- **äººç‰©**: PATIENT, DOCTOR, FAMILYNAME, PERSONALNAME
- **è·æ¥­**: PROFESSION
- **åœ°é»**: ROOM, DEPARTMENT, HOSPITAL, STREET, CITY, DISTRICT, COUNTY, STATE, COUNTRY
- **æ™‚é–“**: AGE, DATE, TIME, DURATION, SET
- **è¯çµ¡**: PHONE

## ğŸ”§ é€²éšé…ç½®

### éŸ³é »è™•ç†é…ç½®

```python
# è‡ªå®šç¾©éŸ³é »è™•ç†é…ç½®
config = ProcessingConfig(
    sr=22050,                    # æ¡æ¨£ç‡
    n_fft=2048,                  # FFT çª—å£å¤§å°
    use_neural_enhancement=True,  # å•Ÿç”¨ç¥ç¶“ç¶²çµ¡å¢å¼·
    use_mixed_precision=True,     # æ··åˆç²¾åº¦è¨ˆç®—
    max_batch_size=16            # æ‰¹æ¬¡å¤§å°
)
```

### NER æ¨¡å‹é…ç½®

```python
# è¨“ç·´åƒæ•¸é…ç½®
training_args = TrainingArguments(
    output_dir="./ner_results",
    learning_rate=3e-5,
    num_train_epochs=40,
    per_device_train_batch_size=4,
    weight_decay=0.03
)
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **CUDA è¨˜æ†¶é«”ä¸è¶³**
   ```bash
   # è§£æ±ºæ–¹æ¡ˆï¼šæ¸›å°‘æ‰¹æ¬¡å¤§å°
   --per_device_batch_size=2
   # æˆ–å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»
   --gradient_checkpointing=True
   ```

2. **Ollama é€£ç·šå¤±æ•—**
   ```bash
   # ç¢ºèª Ollama æœå‹™é‹è¡Œ
   ollama list
   ollama run qwen3:8b
   ```

3. **éŸ³é »æ ¼å¼ä¸æ”¯æ´**
   ```bash
   # è½‰æ›ç‚ºæ”¯æ´æ ¼å¼
   ffmpeg -i input.mp3 -ar 16000 output.wav
   ```

### æ•ˆèƒ½å„ªåŒ–å»ºè­°

- **ä½¿ç”¨ GPU åŠ é€Ÿ**: ç¢ºä¿å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch
- **æ··åˆç²¾åº¦è¨“ç·´**: å•Ÿç”¨ AMP å¯ç¯€çœ 50% è¨˜æ†¶é«”
- **æ‰¹æ¬¡è™•ç†**: å¢åŠ æ‰¹æ¬¡å¤§å°å¯æå‡ GPU åˆ©ç”¨ç‡
- **æ¨¡å‹é‡åŒ–**: ä½¿ç”¨ INT8 é‡åŒ–æ¸›å°‘æ¨ç†æ™‚é–“

## ğŸ“ˆ è©•ä¼°æŒ‡æ¨™

### Task 1 è©•ä¼°
- **å­—ç¬¦éŒ¯èª¤ç‡ (CER)**: å­—ç¬¦ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **è©éŒ¯èª¤ç‡ (WER)**: è©ç´šåˆ¥çš„è­˜åˆ¥éŒ¯èª¤ç‡
- **è™•ç†é€Ÿåº¦**: ç›¸å°æ–¼å¯¦æ™‚çš„è™•ç†å€é€Ÿ

### Task 2 è©•ä¼°
- **ç²¾ç¢ºç‡ (Precision)**: TP / (TP + FP)
- **å¬å›ç‡ (Recall)**: TP / (TP + FN)
- **F1 åˆ†æ•¸**: ç²¾ç¢ºç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡
- **å®å¹³å‡ F1**: æ‰€æœ‰å¯¦é«”é¡åˆ¥ F1 çš„å¹³å‡å€¼

## ğŸ”— ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡æª”
- [AI Cup 2025 å®˜ç¶²](https://aidea-web.tw/)
- [æ¯”è³½è¦å‰‡èˆ‡è©•åˆ†æ¨™æº–](https://aidea-web.tw/topic/cbea3c74-d86b-48c8-8c83-957b2e1374f2)

### æŠ€è¡“æ–‡æª”
- [WhisperX GitHub](https://github.com/m-bain/whisperX)
- [XLM-RoBERTa](https://huggingface.co/FacebookAI/xlm-roberta-large)
- [Ollama å®˜ç¶²](https://ollama.ai/)
- [TorchCRF](https://pytorch-crf.readthedocs.io/)

### å­¸è¡“è«–æ–‡
- [Whisper: Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)
- [XLM-RoBERTa: Unsupervised Cross-lingual Representation Learning](https://arxiv.org/abs/1911.02116)
- [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](https://repository.upenn.edu/cis_papers/159/)

## ğŸ‘¥ è²¢ç»æŒ‡å—

æˆ‘å€‘æ­¡è¿ç¤¾ç¾¤è²¢ç»ï¼è«‹åƒè€ƒä»¥ä¸‹æ­¥é©Ÿï¼š

1. **Fork å°ˆæ¡ˆ**: å»ºç«‹è‡ªå·±çš„å°ˆæ¡ˆåˆ†æ”¯
2. **å»ºç«‹åŠŸèƒ½åˆ†æ”¯**: `git checkout -b feature/amazing-feature`
3. **æäº¤è®Šæ›´**: `git commit -m 'Add amazing feature'`
4. **æ¨é€åˆ†æ”¯**: `git push origin feature/amazing-feature`
5. **å»ºç«‹ Pull Request**: è©³ç´°æè¿°è®Šæ›´å…§å®¹

### é–‹ç™¼è¦ç¯„
- éµå¾ª PEP 8 Python ç¨‹å¼ç¢¼é¢¨æ ¼
- æ–°åŠŸèƒ½éœ€é™„å¸¶æ¸¬è©¦æ¡ˆä¾‹
- æ›´æ–°ç›¸æ‡‰çš„æ–‡æª”èªªæ˜
- æäº¤è¨Šæ¯ä½¿ç”¨è‹±æ–‡ä¸¦æè¿°æ¸…æ¥š

## ğŸ“ æ›´æ–°æ—¥èªŒ

### v2.0.0 (2025-06-12)
- âœ¨ æ–°å¢ Transformer ç¥ç¶“ç¶²çµ¡éŸ³é »å¢å¼·
- âœ¨ æ•´åˆ WhisperX + Ollama å®Œæ•´èªéŸ³è­˜åˆ¥æµç¨‹
- âœ¨ å¯¦ç¾ CRF + FGM å°æŠ—è¨“ç·´ NER æ¨¡å‹
- âœ¨ åŠ å…¥å¿ƒç†è²å­¸å»ºæ¨¡èˆ‡ GPU æ··åˆç²¾åº¦è¨ˆç®—
- ğŸ”§ å„ªåŒ–æ•¸æ“šé›†åˆ†å‰²èˆ‡ K-fold äº¤å‰é©—è­‰
- ğŸ“š å®Œå–„æŠ€è¡“æ–‡æª”èˆ‡ä½¿ç”¨èªªæ˜

### v1.0.0 (2025-05-01)
- ğŸ‰ å°ˆæ¡ˆåˆå§‹ç‰ˆæœ¬
- âœ¨ åŸºç¤éŸ³é »é è™•ç†åŠŸèƒ½
- âœ¨ Whisper èªéŸ³è­˜åˆ¥æ•´åˆ
- âœ¨ XLM-RoBERTa NER æ¨¡å‹
- ğŸ“š åŸºç¤èªªæ˜æ–‡æª”

## ğŸ“„ æˆæ¬Šæ¢æ¬¾

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚è©³è¦‹ [LICENSE](LICENSE) æª”æ¡ˆã€‚

## ğŸ™ è‡´è¬

æ„Ÿè¬ä»¥ä¸‹é–‹æºå°ˆæ¡ˆèˆ‡ç ”ç©¶åœ˜éšŠï¼š

- **OpenAI**: Whisper èªéŸ³è­˜åˆ¥æ¨¡å‹
- **Hugging Face**: Transformers èˆ‡ XLM-RoBERTa æ¨¡å‹
- **Facebook AI**: XLM-RoBERTa é è¨“ç·´æ¨¡å‹
- **PyTorch åœ˜éšŠ**: æ·±åº¦å­¸ç¿’æ¡†æ¶æ”¯æ´
- **Ollama**: æœ¬åœ° LLM éƒ¨ç½²è§£æ±ºæ–¹æ¡ˆ

## ğŸ“§ è¯çµ¡è³‡è¨Š

- **å°ˆæ¡ˆç¶­è­·**: AI Cup 2025 åœ˜éšŠ
- **å•é¡Œå›å ±**: GitHub Issues
- **æŠ€è¡“è¨è«–**: GitHub Discussions
- **é›»å­éƒµä»¶**: [your-email@domain.com]

---

<div align="center">

**ğŸ† AI Cup 2025 - æ¨å‹•é†«ç™‚ AI æŠ€è¡“ç™¼å±• ğŸš€**

[â­ çµ¦æˆ‘å€‘ä¸€é¡†æ˜Ÿ](https://github.com/your-repo/ai_cup_2025) | [ğŸ“š æŸ¥çœ‹æ–‡æª”](https://github.com/your-repo/ai_cup_2025/wiki) | [ğŸ› å›å ±å•é¡Œ](https://github.com/your-repo/ai_cup_2025/issues)

</div>